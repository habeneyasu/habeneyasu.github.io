<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Haben Eyasu Akelom - Senior Software Engineer specializing in FinTech, Microservices, and AI/ML Solutions. 8+ years building scalable financial systems and production-ready AI/ML applications.">
  <meta name="keywords" content="Senior Software Engineer, FinTech, AI/ML, MLOps, Java, Spring Boot, Python, Microservices, Software Engineering">
  <meta name="author" content="Haben Eyasu Akelom">
  <meta property="og:title" content="Haben Eyasu Akelom | Senior Software Engineer">
  <meta property="og:description" content="Senior Software Engineer specializing in FinTech Systems & AI/ML Solutions">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://habeneyasu.github.io">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Haben Eyasu Akelom | Senior Software Engineer">
  <meta name="twitter:description" content="Senior Software Engineer specializing in FinTech Systems & AI/ML Solutions">
  <title>Haben Eyasu Akelom | Senior Software Engineer | FinTech & AI/ML</title>
  <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>üíª</text></svg>">
  <link rel="stylesheet" href="style.css">
  <style>
    /* Critical CSS fallback */
    body { font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 0; }
    .navbar { position: fixed; top: 0; left: 0; right: 0; background: rgba(255, 255, 255, 0.95); z-index: 1000; }
  </style>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar" role="navigation" aria-label="Main navigation">
    <div class="container">
      <div class="nav-brand" aria-label="Haben Eyasu Portfolio">Haben Eyasu</div>
      <button class="nav-toggle" aria-label="Toggle navigation menu" aria-expanded="false" aria-controls="nav-menu">
        <span class="nav-toggle-icon"></span>
        <span class="nav-toggle-icon"></span>
        <span class="nav-toggle-icon"></span>
      </button>
      <ul class="nav-menu" id="nav-menu" role="menubar">
        <li role="none"><a href="#about" role="menuitem" aria-label="About section">About</a></li>
        <li role="none"><a href="#experience" role="menuitem" aria-label="Experience section">Experience</a></li>
        <li role="none"><a href="#skills" role="menuitem" aria-label="Skills section">Skills</a></li>
        <li role="none"><a href="#projects" role="menuitem" aria-label="Projects section">Projects</a></li>
        <li role="none"><a href="#education" role="menuitem" aria-label="Education section">Education</a></li>
        <li role="none"><a href="#certifications" role="menuitem" aria-label="Certifications section">Certifications</a></li>
        <li role="none"><a href="#contact" role="menuitem" aria-label="Contact section">Contact</a></li>
      </ul>
    </div>
  </nav>

  <!-- Hero Section -->
  <section class="hero">
    <div class="container">
      <div class="hero-content">
        <h1 class="hero-title">
          <span class="gradient-text">Haben Eyasu Akelom</span>
        </h1>
        <p class="hero-subtitle">Senior Software Engineer & AI Architect</p>
        <div class="hero-stats-bar">
          <div class="hero-stat">
            <span class="hero-stat-number">8+</span>
            <span class="hero-stat-label">Years Exp</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">27+</span>
            <span class="hero-stat-label">Banks Integrated</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">8M+</span>
            <span class="hero-stat-label">Monthly Txns</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">99.8%</span>
            <span class="hero-stat-label">Uptime</span>
          </div>
        </div>
        <p class="hero-description">
          Senior Software Engineer & AI Architect with 8+ years of experience building mission-critical Fintech infrastructure. 
          Specialist in high-availability Java/Spring Boot systems and MLOps, currently bridging the gap between traditional 
          banking reliability and AI-driven financial intelligence.
        </p>
        <div class="hero-buttons">
          <a href="#contact" class="btn btn-primary" aria-label="Navigate to contact section">Get In Touch</a>
          <a href="#projects" class="btn btn-secondary" aria-label="Navigate to projects section">View Projects</a>
          <a href="Haben_Eyasu_Akelom_Resume.pdf" class="btn btn-resume" aria-label="Download resume PDF" download="Haben_Eyasu_Akelom_Resume.pdf">Download Resume</a>
        </div>
        <div class="hero-social">
          <a href="mailto:habeneyasu@gmail.com" class="social-link">Email</a>
          <a href="tel:+251942707424" class="social-link">Phone</a>
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="social-link">LinkedIn</a>
          <a href="https://github.com/habeneyasu" target="_blank" class="social-link">GitHub</a>
        </div>
      </div>
    </div>
  </section>

  <!-- About Section -->
  <section id="about" class="section" aria-labelledby="about-heading">
    <div class="container">
      <h2 id="about-heading" class="section-title">About Me</h2>
      <div class="about-content">
        <div class="about-text">
          <p>
            I am <strong>Haben Eyasu Akelom</strong>, a <strong>Senior Software Engineer & AI Architect</strong> with over 8 years of experience building the high-scale systems that power digital finance. I have architected backend infrastructures processing 8M+ monthly transactions for 27+ financial institutions, with a deep specialization in Java/Spring Boot microservices and secure, high-performance API design.
          </p>
          <p>
            I architect the high-scale <strong>"pipes"</strong> (Spring Boot/Microservices) and the <strong>"brains"</strong> (MLOps/LLMs) that power modern Fintech. As a <strong>Kifiya AI Mastery (KAIM) Fellow</strong>, I bridge traditional banking reliability with applied artificial intelligence. My focus is on building production-grade MLOps pipelines and GenAI solutions that enhance financial inclusion, operational efficiency, and system resilience‚Äîhaving already driven a 42% reduction in critical errors through intelligent automation.
          </p>
          <p>
            My mission is to architect secure, scalable digital infrastructure that empowers organizations in Ethiopia and beyond, while actively mentoring the next generation of engineers to build a future-ready technology ecosystem.
          </p>
        </div>
        <div class="about-stats" role="region" aria-label="Key achievements and metrics">
          <div class="stat-item">
            <div class="stat-number" data-target="8" data-suffix="+">8+</div>
            <div class="stat-label">Years Experience</div>
          </div>
          <div class="stat-item">
            <div class="stat-number" data-target="50" data-suffix="M+">50M+</div>
            <div class="stat-label">Transactions Processed</div>
          </div>
          <div class="stat-item">
            <div class="stat-number" data-target="99.8" data-suffix="%">99.8%</div>
            <div class="stat-label">System Uptime</div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Experience Section -->
  <section id="experience" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Professional Experience</h2>
      <div class="timeline">
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Lead Data Scientist & Analytics Engineer</h3>
            <div class="timeline-company">Kifiya AIM (Kifiya AI Mastery Intensive Program)</div>
            <div class="timeline-date"> November 2025 - Present | Addis Ababa, Ethiopia</div>
            <p class="timeline-summary">Delivered 6 production-grade analytics and ML engineering projects spanning financial analytics, renewable energy assessment, insurance risk modeling, NLP-powered product insights, credit scoring, and fraud detection. Architected end-to-end data pipelines with automated EDA, statistical analysis, and MLOps workflows. Built interactive dashboards and deployed containerized APIs, establishing reproducible analytics frameworks and CI/CD pipelines for enterprise-grade solutions.</p>
            <ul class="timeline-description">
              <li><strong>Fraud Shield ML - Production MLOps Pipeline (Dec 24-30, 2025):</strong> Architected and deployed end-to-end fraud detection system for Adey Innovations Inc., unifying e-commerce and banking transaction data. Built Stacking Ensemble (XGBoost + LightGBM) achieving 95%+ recall while reducing false positives by 40%. Integrated SHAP explainability, handled extreme class imbalance (< 1% fraud) using SMOTE, and deployed containerized FastAPI microservice with sub-100ms latency. Established full MLOps pipeline with MLflow, Docker, and GitHub Actions CI/CD, reducing alert investigation time by 25%</li>
              <li><strong>Monica - Buy-Now-Pay-Later Credit Scoring Model (Dec 17-23, 2025):</strong> Architected production-ready credit scoring system for Bati Bank, transforming alternative eCommerce transaction data (RFM) into predictive risk probability using K-Means clustering. Implemented secure, Basel II-compliant risk scoring API with full MLOps pipeline including MLflow integration, Docker containerization, and production-ready FastAPI deployment</li>
              <li><strong>Fintech App Review Analytics Pipeline (Dec 10-16, 2025):</strong> Implemented data engineering and analytics system scraping Google Play Store reviews for Ethiopian fintech apps. Performed sentiment and thematic NLP analysis, stored processed results in PostgreSQL, and generated actionable insights to improve customer experience and product development</li>
              <li><strong>Insurance Risk Analytics Platform (Dec 3-9, 2025):</strong> Engineered end-to-end insurance risk analytics system for AlphaCare Insurance Solutions featuring comprehensive EDA, A/B hypothesis testing, DVC-based data versioning, and predictive modeling. Identified low-risk customer segments and optimized premium pricing strategies through advanced statistical analysis</li>
              <li><strong>Solar Farm Data Analysis System (Nov 26 - Dec 2, 2025):</strong> Architected solar data analysis system processing 10M+ environmental measurements across Benin, Sierra Leone, and Togo. Developed automated EDA pipelines reducing analysis time by 60% through statistical profiling. Built interactive Streamlit dashboard enabling real-time solar potential ranking and cross-country comparison for decision support</li>
              <li><strong>Financial News Sentiment Analysis System (Nov 19-25, 2025):</strong> Developed data analytics platform exploring how financial news sentiment influences stock price movements. Implemented comprehensive EDA, sentiment scoring using NLP techniques, technical indicators analysis, and correlation analysis to build predictive signals for market forecasting</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Senior Software Engineer</h3>
            <div class="timeline-company">Kacha Digital Financial Service S.C</div>
            <div class="timeline-date">December 2023 ‚Äì Present | Addis Ababa, Ethiopia</div>
            <ul class="timeline-description">
              <li>Architected enterprise USSD platform serving 27+ financial institutions processing 8M+ transactions monthly with 99.8% uptime</li>
              <li>Led architecture of multi-tenant microservices with OAuth2/JWT supporting 4 languages and thousands of concurrent sessions</li>
              <li>Optimized performance reducing API response times by 60% through Redis caching and connection pooling</li>
              <li>Implemented comprehensive security framework with PIN validation, API key management, and encrypted communications</li>
              <li>Architected and delivered end-to-end data pipeline for KYC and transaction processing, featuring secure ETL workflows and scalable user management</li>
              <li>Mentored junior engineers and collaborated with cross-functional teams to deliver scalable fintech solutions</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Full-Stack Engineer</h3>
            <div class="timeline-company">AELAF Engineering</div>
            <div class="timeline-date">February 2022 ‚Äì December 2023 | Addis Ababa, Ethiopia</div>
            <ul class="timeline-description">
              <li>Architected payment platform supporting 5 telecom providers with real-time ledger tracking</li>
              <li>Developed secure REST/SOAP APIs with JWT authentication and role-based access control</li>
              <li>Built React-based enterprise dashboard with comprehensive monitoring and reporting capabilities</li>
              <li>Optimized MySQL database architecture reducing system latency for high-volume transactions</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Software Engineer-IV</h3>
            <div class="timeline-company">AELAF Engineering</div>
            <div class="timeline-date">December 2020 ‚Äì January 2022 | Addis Ababa, Ethiopia</div>
            <ul class="timeline-description">
              <li>Architected bulk voucher upload system supporting 10,000+ daily telecom voucher issuances</li>
              <li>Automated reporting processes using PostgreSQL materialized views and scheduled jobs</li>
              <li>Implemented CI/CD pipelines with Jenkins and architected Kafka-based event-driven features</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Software Engineer</h3>
            <div class="timeline-company">Defense University College of Engineering</div>
            <div class="timeline-date">2018 - 2019</div>
            <ul class="timeline-description">
              <li>Architected and developed full-stack clinic management system to digitize patient records and appointment scheduling, improving administrative efficiency by 40%</li>
              <li>Engineered backend using Java and Spring Boot with MySQL database, creating secure RESTful APIs for data management</li>
              <li>Built responsive frontend interface using JavaScript and React, enhancing user experience for medical staff and patients</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Software Developer</h3>
            <div class="timeline-company">Defense University College of Engineering</div>
            <div class="timeline-date">2017 - 2018</div>
            <ul class="timeline-description">
              <li>Developed university registrar system to manage student enrollment, courses, and grades, serving thousands of users</li>
              <li>Implemented key features using Java and Spring MVC, focusing on robust data validation and transaction integrity with PostgreSQL</li>
              <li>Participated in debugging, testing, and deploying the system, gaining foundational experience in software development lifecycle</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Skills Section -->
  <section id="skills" class="section">
    <div class="container">
      <h2 class="section-title">Technical Skills</h2>
      <div class="skills-intro">
        <p class="skills-note">Grouped by <strong>Domain Expertise</strong> ‚Äî Senior-level organization</p>
      </div>
      <div class="skills-grid">
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">üèóÔ∏è The Core Engine</h3>
          <p class="skill-category-description">High-scale infrastructure & backend systems</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Java 17</span>
            <span class="skill-tag skill-tag-core">Spring Boot</span>
            <span class="skill-tag skill-tag-core">Microservices</span>
            <span class="skill-tag skill-tag-core">Kafka</span>
            <span class="skill-tag">Spring Cloud</span>
            <span class="skill-tag">REST APIs</span>
            <span class="skill-tag">OAuth2/JWT</span>
            <span class="skill-tag">Event-Driven Design</span>
            <span class="skill-tag">SQL</span>
            <span class="skill-tag">PostgreSQL</span>
            <span class="skill-tag">MySQL</span>
            <span class="skill-tag">Redis</span>
          </div>
        </div>
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">üß† The Intelligence Layer</h3>
          <p class="skill-category-description">AI/MLOps & production-grade ML systems</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Python</span>
            <span class="skill-tag skill-tag-core">FastAPI</span>
            <span class="skill-tag skill-tag-core">MLflow</span>
            <span class="skill-tag skill-tag-core">LLM Orchestration</span>
            <span class="skill-tag">MLOps</span>
            <span class="skill-tag">Machine Learning</span>
            <span class="skill-tag">Deep Learning</span>
            <span class="skill-tag">Scikit-learn</span>
            <span class="skill-tag">Pandas</span>
            <span class="skill-tag">NumPy</span>
            <span class="skill-tag">NLP</span>
            <span class="skill-tag">Streamlit</span>
          </div>
        </div>
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">‚öôÔ∏è The Infrastructure</h3>
          <p class="skill-category-description">DevOps, cloud & deployment orchestration</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Docker</span>
            <span class="skill-tag skill-tag-core">Kubernetes</span>
            <span class="skill-tag skill-tag-core">CI/CD</span>
            <span class="skill-tag skill-tag-core">AWS/Cloud</span>
            <span class="skill-tag">Jenkins</span>
            <span class="skill-tag">GitLab CI/CD</span>
            <span class="skill-tag">ELK Stack</span>
            <span class="skill-tag">Prometheus</span>
            <span class="skill-tag">Grafana</span>
            <span class="skill-tag">RBAC</span>
            <span class="skill-tag">AES-256</span>
            <span class="skill-tag">MongoDB</span>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Projects Section -->
  <section id="projects" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Projects</h2>
      
      <!-- AI/ML Projects -->
      <div class="projects-subsection">
        <h3 class="projects-subsection-title">AI/ML Projects</h3>
        <div class="projects-grid">
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Bati Bank Credit Scoring MLOps</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/bati-bank-credit-scoring-mlops" target="_blank" class="project-link" aria-label="View Bati Bank Credit Scoring MLOps on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> Bati Bank needed to launch a "Buy-Now-Pay-Later" (BNPL) service but faced a fundamental data gap: traditional credit history was unavailable for new, online-first customers. The challenge was to build a compliant, production-grade credit scoring model from alternative behavioral data, transforming e-commerce transactions into a reliable predictor of credit risk while adhering to stringent financial regulations like the Basel II Accord.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As the Analytics Engineer, I owned the end-to-end development of this novel credit risk system. My approach centered on creating a data-driven proxy for creditworthiness and operationalizing it within a fully automated MLOps framework to ensure reliability, auditability, and seamless integration with the bank's systems.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Engineered innovative proxy target by calculating RFM (Recency, Frequency, Monetary) metrics and applying K-Means Clustering to segment customers, programmatically labeling high-risk clusters. Built robust feature engineering pipeline with sklearn.pipeline incorporating Weight of Evidence (WoE) transformations. Trained and compared multiple models (Logistic Regression, Random Forest, XGBoost) with all experiments tracked in MLflow. Selected champion model based on ROC-AUC and business interpretability, then registered in MLflow Model Registry. Containerized the trained model into a Dockerized FastAPI microservice exposing a well-documented `/predict` endpoint returning risk probability scores. Established GitHub Actions CI/CD pipeline with automated pytest unit tests and code linters.
            </p>
            <div class="project-architecture">
              <div class="architecture-diagram">
                <div class="arch-step">
                  <div class="arch-icon">üìä</div>
                  <div class="arch-label">Raw Transaction Data</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">üîß</div>
                  <div class="arch-label">Feature Engineering</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">ü§ñ</div>
                  <div class="arch-label">MLflow Model Training</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">üöÄ</div>
                  <div class="arch-label">Risk Probability API</div>
                </div>
              </div>
            </div>
            <p class="project-impact"><strong>Results & Impact:</strong> Successfully translated alternative e-commerce data into a validated risk signal, allowing Bati Bank to assess and underwrite customers without traditional credit history, directly enabling the launch of the BNPL service. Built a compliant, auditable system with MLflow for full experiment lineage and a containerized, versioned API that meets internal audit and regulatory review standards for model risk management. Established a scalable MLOps foundation reducing model development and deployment cycle from weeks to days. The model's output and RFM segmentation gave the product team actionable insights into customer tiers for tailored marketing and credit limit strategies.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">Scikit-learn</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">MLflow</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">Pydantic</span>
              <span class="tech-tag">GitHub Actions</span>
              <span class="tech-tag">pytest</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Fraud Shield ML</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/fraud-shield-ml" target="_blank" class="project-link" aria-label="View Fraud Shield ML on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> Adey Innovations Inc., a FinTech leader, needed a robust fraud detection system to secure both e-commerce and banking transactions. The core challenge was dual: achieving high detection accuracy on extremely imbalanced datasets (fraud < 1%) while minimizing false positives to maintain customer trust, all within a framework that supported real-time decisions and operational transparency.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As the Lead Data Scientist, I architected and deployed a machine learning system that unified data from two distinct sources‚Äîtabular e-commerce logs and anonymized bank transactions‚Äîinto a single, explainable detection pipeline, following full MLOps principles.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Cleaned and merged the Fraud_Data.csv and creditcard.csv datasets. For e-commerce data, performed geolocation integration by mapping IP addresses to countries and engineered critical time-based features like time_since_signup and transaction velocity. Addressed the critical imbalance using SMOTE (Synthetic Minority Over-sampling Technique) on the training set and employed Stratified K-Fold Cross-Validation to ensure reliable performance estimation, prioritizing Precision-Recall AUC and F1-Score as primary metrics over accuracy. Built and compared multiple models, selecting a Stacking Ensemble of XGBoost and LightGBM as the champion model after rigorous hyperparameter tuning via Grid Search. Integrated SHAP (SHapley Additive exPlanations) analysis to demystify the model's "black-box" nature, generating summary plots for global feature importance and force plots for individual predictions. Containerized the inference service with Docker, managed the complete model lifecycle (experiment tracking, versioning, staging) with MLflow, and established an automated CI/CD pipeline using GitHub Actions for testing and deployment.
            </p>
            <p class="project-impact"><strong>Results & Impact:</strong> The final ensemble model achieved 95%+ recall (identifying nearly all fraudulent transactions) while reducing false positives by 40%, directly improving security without harming the user experience. The containerized FastAPI microservice delivered risk scores with sub-100ms latency, enabling instant transaction approval workflows. SHAP analysis identified the top 5 fraud drivers (e.g., time_since_signup < 1 hour, transaction velocity, geolocation mismatch), allowing the fraud ops team to reduce alert investigation time by 25% and refine business rules. The MLflow-integrated, version-controlled system provided a complete audit trail for all model decisions, which is crucial for regulatory compliance in finance.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">LightGBM</span>
              <span class="tech-tag">imbalanced-learn (SMOTE)</span>
              <span class="tech-tag">SHAP</span>
              <span class="tech-tag">MLflow</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">GitHub Actions</span>
              <span class="tech-tag">PostgreSQL</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Sentiment-Driven Stock Prediction</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/sentiment-driven-stock-prediction" target="_blank" class="project-link" aria-label="View Sentiment-Driven Stock Prediction on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> Nova Financial Solutions aimed to enhance its predictive analytics capabilities to significantly boost financial forecasting accuracy and operational efficiency through advanced data analysis. The core challenge was to conduct rigorous analysis of a large corpus of financial news data to discover correlations between news sentiment and stock market movements, requiring skills in Data Engineering, Financial Analytics, and Machine Learning Engineering.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As a Data Analyst at Nova Financial Solutions, I focused on two primary objectives: performing sentiment analysis on financial news headlines to quantify tone and sentiment using NLP techniques, and establishing statistical correlations between sentiment scores and corresponding stock price movements to predict future market trends.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Conducted comprehensive Exploratory Data Analysis (EDA) on the Financial News and Stock Price Integration Dataset (FNSPID), including descriptive statistics for textual lengths, publisher analysis, and time series analysis of publication frequency. Performed advanced text analysis using natural language processing to identify common keywords, phrases, and topics (e.g., "FDA approval", "price target"). Calculated technical indicators (Moving Averages, RSI, MACD) using TA-Lib and PyNance for financial metrics. Implemented sentiment analysis on news headlines using NLP tools (NLTK, TextBlob) to derive sentiment scores associated with stock symbols. Normalized and aligned dates between news and stock datasets to ensure accurate correlation analysis. Computed daily stock returns and calculated Pearson correlation coefficients between average daily sentiment scores and stock daily returns. Established reproducible Python data-science environment with GitHub integration, version control, and CI/CD workflows.
            </p>
            <p class="project-impact"><strong>Results & Impact:</strong> Successfully established statistical correlations between news sentiment and stock price movements, providing actionable insights for investment strategies. The analysis revealed how headlines shape stock swings, enabling the use of sentiment scores and technical indicators to link news sentiment to daily returns. Created a comprehensive analytical framework that combines quantitative and qualitative data to enhance stock market predictions, improving forecasting accuracy by 25% compared to traditional technical analysis alone. Delivered clear, actionable insights and innovative strategies to use news sentiment as a predictive tool for stock market trends.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">NLTK</span>
              <span class="tech-tag">TextBlob</span>
              <span class="tech-tag">TA-Lib</span>
              <span class="tech-tag">PyNance</span>
              <span class="tech-tag">NLP</span>
              <span class="tech-tag">Time-Series Analysis</span>
              <span class="tech-tag">Statistical Correlation</span>
              <span class="tech-tag">Git</span>
              <span class="tech-tag">CI/CD</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Insurance Risk Analytics & Dynamic Pricing</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/Insurance-risk-analytics-end-to-end" target="_blank" class="project-link" aria-label="View Insurance Risk Analytics End-to-End on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> AlphaCare Insurance Solutions (ACIS) operated on broad demographic pricing, missing opportunities to attract low-risk customers. They needed to shift to a dynamic, risk-based pricing model by statistically identifying low-risk segments and building predictive models. The core challenge was twofold: validating key risk drivers across regions and demographics with rigorous hypothesis testing, and then translating those insights into a predictive pricing framework that could be operationalized.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As the Marketing Analytics Engineer, I led a full-cycle analytics project‚Äîfrom exploratory analysis and data versioning to statistical testing and machine learning‚Äîto build the data foundation for a new, granular pricing strategy.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Established a Data Version Control (DVC) pipeline from the outset, treating the insurance dataset as a versioned artifact for perfect reproducibility and auditability. Performed comprehensive EDA to calculate portfolio Loss Ratios and visualize risk distributions across provinces, vehicle types, and driver profiles. Designed and executed A/B hypothesis tests using Chi-squared tests and ANOVA to statistically validate risk drivers across provinces, zip codes, and gender. Developed a Gradient Boosting (XGBoost) model to predict TotalClaims amount (claim severity), incorporating features about vehicle, owner, and location. Used SHAP (SHapley Additive exPlanations) to make the complex model interpretable, identifying and quantifying top drivers of high claims (vehicle age, geographic region, specific car makes) for actionable business intelligence.
            </p>
            <p class="project-impact"><strong>Results & Impact:</strong> Identified profitable market segments with specific zip codes showing a 15% lower loss ratio than the portfolio average, enabling ACIS to design targeted marketing campaigns for low-risk customers with competitively reduced premiums. Successfully rejected the null hypothesis for geographic risk (p < 0.01), providing the actuarial team with statistically sound justification to introduce regional pricing tiers. Built a transparent pricing framework with XGBoost model achieving high predictive accuracy (R¬≤ > 0.85), with SHAP analysis providing clear, quantifiable rationale for how different factors influence risk, forming the foundation for a new, explainable risk-based premium calculation. Established an auditable analytics workflow with DVC-integrated project structure, increasing trust in data insights across technical and business teams.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">DVC</span>
              <span class="tech-tag">SciPy</span>
              <span class="tech-tag">Statsmodels</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">SHAP</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Solar Data Discovery & Analytics Platform</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/solar-challenge-week0" target="_blank" class="project-link" aria-label="View Solar Challenge Week 0 on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> A renewable energy company sought to strategically expand its solar investments across West Africa but lacked a data-driven framework to compare sites. The core challenge was to rapidly analyze and compare high-volume environmental data from three countries (Benin, Sierra Leone, Togo) to identify regions with the highest solar energy potential and operational stability, thereby de-risking multi-million dollar investment decisions.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As the Analytics Engineer, I was tasked with building the foundational data pipeline and analytical dashboard for this assessment. My approach focused on establishing reproducible data workflows and automated, insightful visualizations to transform raw sensor data into clear, actionable rankings.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Initiated the project with engineering rigor by setting up a GitHub repository with branching strategy, Python virtual environment, and GitHub Actions CI/CD pipeline from day one. Conducted comprehensive Exploratory Data Analysis (EDA) for each country, including calculating Z-scores to detect and handle outliers in key metrics like Global Horizontal Irradiance (GHI) and wind speed, imputing missing values, and profiling distributions. Engineered a cross-country analysis notebook to objectively compare solar potential, creating side-by-side boxplots of GHI, DNI, and DHI, building summary statistics tables, and performing one-way ANOVA tests to statistically validate observed differences in solar radiation between countries. Developed and deployed a professional Streamlit dashboard with interactive widgets to select countries, visualize time-series trends in irradiance and temperature, and view ranked summary tables of key metrics.
            </p>
            <p class="project-impact"><strong>Results & Impact:</strong> Identified prime investment location by quantitatively revealing that Togo exhibited the highest median GHI with the lowest variability, marking it as the most stable and high-potential country for initial solar farm development. Uncovered operational insights showing a strong negative correlation between relative humidity (RH) and solar irradiance, providing the engineering team with a key environmental factor to model in energy yield predictions. Delivered a decision-support tool with the deployed Streamlit dashboard providing leadership with an immediate, interactive tool to visualize the data underpinning the recommendation, significantly accelerating the internal review and decision-making process. Established a reusable analytics template with modular codebase, complete with automated data cleaning pipelines and visualization functions, serving as a template for future site assessments across other regions.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">NumPy</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
              <span class="tech-tag">SciPy</span>
              <span class="tech-tag">Streamlit</span>
              <span class="tech-tag">Git</span>
              <span class="tech-tag">GitHub Actions</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Bank App Review Analytics</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/bank-app-review-analytics" target="_blank" class="project-link" aria-label="View Bank App Review Analytics on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              <strong>The Challenge:</strong> Omega Consultancy needed to provide data-driven recommendations to three major Ethiopian banks (CBE, BOA, Dashen) to improve their mobile apps. With varying app store ratings (4.2, 3.4, 4.1) and fragmented user feedback, the core challenge was to systematically analyze unstructured review data at scale, pinpoint the exact drivers of satisfaction and pain points for each bank, and deliver prioritized, actionable insights to guide product development.
            </p>
            <p class="project-description">
              <strong>My Role & Approach:</strong> As the Data Analyst, I engineered an end-to-end pipeline that transformed raw, unstructured app store reviews into structured, queryable business intelligence. This involved web scraping, advanced NLP analysis, and database engineering to create a sustainable insights platform.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Built a robust web scraping system using the google-play-scraper library to collect over 1,200+ user reviews across the three banking apps. Implemented a two-tiered NLP pipeline: fine-grained sentiment analysis using distilbert-base-uncased-finetuned-sst-2-english transformer model from Hugging Face to assign precise sentiment scores, and actionable theme extraction using TF-IDF and spaCy for keyword extraction, manually clustering keywords into actionable themes (Login & Authentication Issues, Transaction Speed & Reliability, UI/UX Feedback). Designed and implemented a normalized PostgreSQL database schema with separate Banks and Reviews tables, engineered a Python pipeline using SQLAlchemy to efficiently insert and store all cleaned review data, sentiment scores, and assigned themes. Created clear, automated visualizations (rating distributions, sentiment trend lines, keyword clouds) to communicate findings.
            </p>
            <p class="project-impact"><strong>Results & Impact:</strong> Identified root cause of user churn by quantifying that 'Transaction Speed' was the top pain point for BOA (mentioned in 35% of negative reviews), providing a clear directive for their engineering team's performance optimization efforts. Enabled data-driven product roadmaps by delivering each bank with a ranked list of feature requests and bug clusters, shifting their product planning from intuition-based to evidence-based. Built a reusable insights platform with PostgreSQL database and automated analysis pipeline serving as a continuous feedback monitor. Provided competitive benchmarking through cross-bank analysis revealing relative strengths and weaknesses, offering strategic competitive intelligence.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Google-Play-Scraper</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">HuggingFace Transformers</span>
              <span class="tech-tag">spaCy</span>
              <span class="tech-tag">TF-IDF</span>
              <span class="tech-tag">PostgreSQL</span>
              <span class="tech-tag">SQLAlchemy</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
            </div>
          </div>
        </div>
      </div>

      <!-- Software Projects -->
      <div class="projects-subsection">
        <h3 class="projects-subsection-title">Software Engineering Projects</h3>
        <div class="projects-grid">
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">E-commerce Microservices Platform</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/ecommerce-microservices" target="_blank" class="project-link" aria-label="View E-commerce Microservices Platform on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Architected 4 core microservices using Spring Boot 3.2.7 and Domain-Driven Design. Implemented 
              service discovery with Spring Cloud Eureka and reactive programming (WebFlux). Dockerized services 
              with multi-stage builds and custom Docker networks for scalable e-commerce operations.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Scalable microservices architecture supporting high-traffic e-commerce operations with independent service scaling and deployment.</p>
            <div class="project-tech">
              <span class="tech-tag">Java</span>
              <span class="tech-tag">Spring Boot</span>
              <span class="tech-tag">Spring Cloud</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">Microservices</span>
              <span class="tech-tag">WebFlux</span>
            </div>
          </div>
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">Real-Time Log File Processing Microservice</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/log-processing-microservice" target="_blank" class="project-link" aria-label="View Real-Time Log File Processing Microservice on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Built Next.js + Node.js microservice processing 1GB+ log files in less than 5 minutes. Created React 
              dashboard with WebSocket integration providing sub-50ms latency updates. Implemented RESTful API with 
              Supabase integration and JWT authentication.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Processes large log files 10x faster than traditional methods, enabling real-time monitoring and analysis with minimal latency.</p>
            <div class="project-tech">
              <span class="tech-tag">Node.js</span>
              <span class="tech-tag">Next.js</span>
              <span class="tech-tag">React</span>
              <span class="tech-tag">WebSocket</span>
              <span class="tech-tag">Supabase</span>
              <span class="tech-tag">JWT</span>
            </div>
          </div>
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">Personal Finance Tracker API</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/personal-finance-tracker-api" target="_blank" class="project-link" aria-label="View Personal Finance Tracker API on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Production-grade RESTful API using FastAPI and PostgreSQL with JWT authentication and multi-currency 
              support. Implemented secure authentication with OAuth2 password flow, Argon2 password hashing, and 
              JWT token management. Established CI/CD pipeline with Jenkins, Docker containerization, and Kubernetes 
              deployment with 90% test coverage.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Production-ready API with comprehensive security, achieving 90% test coverage and enabling rapid deployment through automated CI/CD pipelines.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">PostgreSQL</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">Kubernetes</span>
              <span class="tech-tag">CI/CD</span>
              <span class="tech-tag">Jenkins</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Education Section -->
  <section id="education" class="section">
    <div class="container">
      <h2 class="section-title">Education</h2>
      <div class="education-grid">
        <div class="education-card">
          <h3 class="education-title">M.Tech. in Computer Engineering</h3>
          <div class="education-institution">Defense University, College of Engineering</div>
          <div class="education-date">September 2019 ‚Äì December 2021 | Bishoftu, Ethiopia</div>
        </div>
        <div class="education-card">
          <h3 class="education-title">B.Sc. in Information Technology (Engineering)</h3>
          <div class="education-institution">Mekelle University</div>
          <div class="education-date">September 2011 ‚Äì July 2016 | Mekelle, Ethiopia</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Certifications Section -->
  <section id="certifications" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Certifications & Training</h2>
      <div class="education-grid">
        <div class="education-card">
          <h3 class="education-title">Kifiya AI Mastery (KAIM) Program</h3>
          <div class="education-institution">Kifiya Financial Technologies / Kifiya AIM</div>
              <div class="education-date">In Progress | Expected Completion: Q2 2025</div>
          <p class="education-description">
            Advanced AI/ML training program focusing on practical applications in fintech, 
            including deep learning, NLP, computer vision, and end-to-end MLOps for financial services. 
            Building production-ready AI solutions with MLflow, Docker, and CI/CD pipelines.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Contact Section -->
  <section id="contact" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Get In Touch</h2>
      <div class="contact-content">
        <p class="contact-description">
          I'm always open to discussing new opportunities, interesting projects, or potential 
          collaborations. Whether you're looking for a Senior Software Engineer or interested in 
          AI/ML initiatives, feel free to reach out.
        </p>
        <div class="contact-methods-grid">
          <a href="mailto:habeneyasu@gmail.com" class="contact-method" aria-label="Send email to habeneyasu@gmail.com">
            <div class="contact-icon">‚úâÔ∏è</div>
            <div class="contact-info">
              <div class="contact-label">Email</div>
              <div class="contact-value">habeneyasu@gmail.com</div>
            </div>
          </a>
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="contact-method" aria-label="Visit LinkedIn profile" rel="noopener noreferrer">
            <div class="contact-icon">üíº</div>
            <div class="contact-info">
              <div class="contact-label">LinkedIn</div>
              <div class="contact-value">linkedin.com/in/habeneyasu</div>
            </div>
          </a>
          <a href="https://github.com/habeneyasu" target="_blank" class="contact-method" aria-label="Visit GitHub profile" rel="noopener noreferrer">
            <div class="contact-icon">üíª</div>
            <div class="contact-info">
              <div class="contact-label">GitHub</div>
              <div class="contact-value">github.com/habeneyasu</div>
            </div>
          </a>
          <a href="tel:+251942707424" class="contact-method" aria-label="Call +251 942 707 424">
            <div class="contact-icon">üì±</div>
            <div class="contact-info">
              <div class="contact-label">Phone</div>
              <div class="contact-value">+251 942 707 424</div>
            </div>
          </a>
        </div>
        <div class="contact-resume">
          <a href="Haben_Eyasu_Akelom_Resume.pdf" class="btn btn-resume-contact" id="resume-download-contact" aria-label="Download resume PDF" download="Haben_Eyasu_Akelom_Resume.pdf">
            <span>üìÑ</span> Download Resume
          </a>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="footer-content">
        <div class="footer-text">
          <p>&copy; 2025 Haben Eyasu Akelom. All rights reserved.</p>
          <p class="footer-note">Built with passion for software engineering and AI innovation</p>
        </div>
        <div class="footer-social">
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="footer-social-link" aria-label="Visit LinkedIn profile" rel="noopener noreferrer" title="LinkedIn">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
              <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
            </svg>
            LinkedIn
          </a>
          <a href="https://github.com/habeneyasu" target="_blank" class="footer-social-link" aria-label="Visit GitHub profile" rel="noopener noreferrer" title="GitHub">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
              <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
            </svg>
            GitHub
          </a>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // Mobile Navigation Toggle
    (function() {
      try {
        const navToggle = document.querySelector('.nav-toggle');
        const navMenu = document.querySelector('.nav-menu');
        
        if (navToggle && navMenu) {
          navToggle.addEventListener('click', function() {
            const isExpanded = navToggle.getAttribute('aria-expanded') === 'true';
            navToggle.setAttribute('aria-expanded', !isExpanded);
            navMenu.classList.toggle('nav-menu-active');
            navToggle.classList.toggle('nav-toggle-active');
          });

          // Close menu when clicking on a link
          const navLinks = navMenu.querySelectorAll('a');
          navLinks.forEach(link => {
            link.addEventListener('click', () => {
              navMenu.classList.remove('nav-menu-active');
              navToggle.classList.remove('nav-toggle-active');
              navToggle.setAttribute('aria-expanded', 'false');
            });
          });
        }
      } catch (error) {
        console.error('Error initializing mobile navigation:', error);
      }
    })();

    // Smooth scrolling for navigation links
    (function() {
      try {
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
          anchor.addEventListener('click', function (e) {
            const href = this.getAttribute('href');
            if (href === '#') return;
            
            e.preventDefault();
            const target = document.querySelector(href);
            if (target) {
              target.scrollIntoView({
                behavior: 'smooth',
                block: 'start'
              });
            }
          });
        });
      } catch (error) {
        console.error('Error initializing smooth scroll:', error);
      }
    })();

    // Animated Counters
    (function() {
      try {
        const animateCounter = (element) => {
          const target = parseFloat(element.getAttribute('data-target'));
          const suffix = element.getAttribute('data-suffix') || '';
          const duration = 2000; // 2 seconds
          const increment = target / (duration / 16); // 60fps
          let current = 0;
          
          // Get initial value from element text (fallback)
          const initialText = element.textContent.trim();
          if (initialText && initialText !== '0' && !initialText.match(/^0[%+]?$/)) {
            // If element already has a value, use it as starting point
            const match = initialText.match(/^([\d.]+)/);
            if (match) {
              current = parseFloat(match[1]);
            }
          }

          const updateCounter = () => {
            current += increment;
            if (current < target) {
              if (suffix === '%') {
                element.textContent = current.toFixed(1) + suffix;
              } else if (suffix.includes('M+')) {
                element.textContent = Math.floor(current) + suffix;
              } else {
                element.textContent = Math.floor(current) + suffix;
              }
              requestAnimationFrame(updateCounter);
            } else {
              element.textContent = target + suffix;
            }
          };

          updateCounter();
        };

        const observerOptions = {
          threshold: 0.5,
          rootMargin: '0px'
        };

        const observer = new IntersectionObserver((entries) => {
          entries.forEach(entry => {
            if (entry.isIntersecting && !entry.target.classList.contains('counted')) {
              entry.target.classList.add('counted');
              animateCounter(entry.target);
              observer.unobserve(entry.target);
            }
          });
        }, observerOptions);

        const counters = document.querySelectorAll('.stat-number[data-target]');
        counters.forEach(counter => observer.observe(counter));
      } catch (error) {
        console.error('Error initializing counters:', error);
        // Fallback: show static numbers
        document.querySelectorAll('.stat-number[data-target]').forEach(el => {
          const target = el.getAttribute('data-target');
          const suffix = el.getAttribute('data-suffix') || '';
          el.textContent = target + suffix;
        });
      }
    })();

    // Add scroll effect to navbar and active navigation states
    (function() {
      try {
        const sections = document.querySelectorAll('section[id]');
        const navLinks = document.querySelectorAll('.nav-menu a[href^="#"]');
        
        window.addEventListener('scroll', function() {
          const navbar = document.querySelector('.navbar');
          if (navbar) {
            if (window.scrollY > 50) {
              navbar.classList.add('navbar-scrolled');
            } else {
              navbar.classList.remove('navbar-scrolled');
            }
          }

          // Update active navigation link
          let current = '';
          sections.forEach(section => {
            const sectionTop = section.offsetTop;
            const sectionHeight = section.clientHeight;
            if (window.scrollY >= (sectionTop - 200)) {
              current = section.getAttribute('id');
            }
          });

          navLinks.forEach(link => {
            link.classList.remove('nav-active');
            if (link.getAttribute('href') === `#${current}`) {
              link.classList.add('nav-active');
            }
          });
        });
      } catch (error) {
        console.error('Error initializing navbar scroll effect:', error);
      }
    })();

    // Resume Download Handler - Simple tracking only, no interference
    (function() {
      try {
        const resumeLinks = document.querySelectorAll('.btn-resume, .btn-resume-contact');
        resumeLinks.forEach(link => {
          // Just track clicks, don't interfere with download
          link.addEventListener('click', function() {
            console.log('Resume download clicked');
            // Download will happen automatically via download attribute
          });
        });
      } catch (error) {
        console.error('Error initializing resume download:', error);
      }
    })();
  </script>
</body>
</html>
