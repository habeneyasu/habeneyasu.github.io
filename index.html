<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Haben Eyasu Akelom - Senior Software Engineer specializing in FinTech, Microservices, and AI/ML Solutions. 8+ years building scalable financial systems and production-ready AI/ML applications.">
  <meta name="keywords" content="Senior Software Engineer, FinTech, AI/ML, MLOps, Java, Spring Boot, Python, Microservices, Software Engineering">
  <meta name="author" content="Haben Eyasu Akelom">
  <meta property="og:title" content="Haben Eyasu Akelom | Senior Software Engineer">
  <meta property="og:description" content="Senior Software Engineer specializing in FinTech Systems & AI/ML Solutions">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://habeneyasu.github.io">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Haben Eyasu Akelom | Senior Software Engineer">
  <meta name="twitter:description" content="Senior Software Engineer specializing in FinTech Systems & AI/ML Solutions">
  <title>Haben Eyasu Akelom | Senior Software Engineer | FinTech & AI/ML</title>
  <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>üíª</text></svg>">
  <link rel="stylesheet" href="style.css">
  <style>
    /* Critical CSS fallback */
    body { font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 0; }
    .navbar { position: fixed; top: 0; left: 0; right: 0; background: rgba(255, 255, 255, 0.95); z-index: 1000; }
  </style>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar" role="navigation" aria-label="Main navigation">
    <div class="container">
      <div class="nav-brand" aria-label="Haben Eyasu Portfolio">Haben Eyasu</div>
      <button class="nav-toggle" aria-label="Toggle navigation menu" aria-expanded="false" aria-controls="nav-menu">
        <span class="nav-toggle-icon"></span>
        <span class="nav-toggle-icon"></span>
        <span class="nav-toggle-icon"></span>
      </button>
      <ul class="nav-menu" id="nav-menu" role="menubar">
        <li role="none"><a href="#about" role="menuitem" aria-label="About section">About</a></li>
        <li role="none"><a href="#experience" role="menuitem" aria-label="Experience section">Experience</a></li>
        <li role="none"><a href="#skills" role="menuitem" aria-label="Skills section">Skills</a></li>
        <li role="none"><a href="#projects-ai-ml" role="menuitem" aria-label="AI/ML Projects section">Projects</a></li>
        <li role="none"><a href="#education" role="menuitem" aria-label="Education section">Education</a></li>
        <li role="none"><a href="#contact" role="menuitem" aria-label="Contact section">Contact</a></li>
      </ul>
    </div>
  </nav>

  <main>
  <!-- Hero Section -->
  <section class="hero">
    <div class="container">
      <div class="hero-content">
        <h1 class="hero-title">
          <span class="gradient-text">Haben Eyasu Akelom</span>
        </h1>
        <h2 class="hero-subtitle">Senior Software & Machine Learning Engineer</h2>
        <p class="hero-value-statement">Architecting scalable fintech platforms and intelligent AI/ML systems</p>
        <div class="hero-stats-bar">
          <div class="hero-stat">
            <span class="hero-stat-number">8+</span>
            <span class="hero-stat-label">Years Exp</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">27+</span>
            <span class="hero-stat-label">Banks Integrated</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">8M+</span>
            <span class="hero-stat-label">Monthly Txns</span>
          </div>
          <span class="hero-stat-divider">|</span>
          <div class="hero-stat">
            <span class="hero-stat-number">99.8%</span>
            <span class="hero-stat-label">Uptime</span>
          </div>
        </div>
        <p class="hero-description">
          Senior Software & Machine Learning Engineer skilled in developing both scalable financial platforms and intelligent AI/ML solutions. 
          Combines proven expertise in high-volume Java/Spring Boot microservices with hands-on experience building end-to-end credit scoring, 
          fraud detection, and financial complaint analysis systems using MLOps best practices. Recently completed a comprehensive AI/ML engineering 
          portfolio through the 10 Academy KAIM Program, delivering 20+ production-ready projects spanning MLOps, data engineering, quantitative finance, 
          and strategic leadership. Applies predictive modeling, NLP, semantic search, and data analytics to deliver actionable insights and measurable business impact.
        </p>
        <div class="hero-buttons">
          <a href="#contact" class="btn btn-primary" aria-label="Navigate to contact section">Get In Touch</a>
          <a href="#projects-ai-ml" class="btn btn-secondary" aria-label="Navigate to projects section">View Projects</a>
          <a href="Haben_Eyasu_Akelom_Resume.pdf" class="btn btn-resume" aria-label="Download resume PDF" download="Haben_Eyasu_Akelom_Resume.pdf">Download Resume</a>
        </div>
        <div class="hero-social">
          <a href="mailto:habeneyasu@gmail.com" class="social-link">Email</a>
          <a href="tel:+251942707424" class="social-link">Phone</a>
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="social-link">LinkedIn</a>
          <a href="https://github.com/habeneyasu" target="_blank" class="social-link">GitHub</a>
        </div>
      </div>
    </div>
  </section>

  <!-- Executive Summary Section -->
  <section id="executive-summary" class="section section-executive">
    <div class="container">
      <div class="executive-summary-box">
        <h2 class="executive-summary-title">Who I Am & What I Deliver</h2>
        <div class="executive-summary-content">
          <p class="executive-summary-text">
            I am a <strong>Senior Software & Machine Learning Engineer</strong> skilled in developing both scalable financial platforms and intelligent AI/ML solutions. 
            I combine proven expertise in high-volume Java/Spring Boot microservices with hands-on experience building end-to-end credit scoring, 
            fraud detection, and financial complaint analysis systems using MLOps best practices.
          </p>
          <p class="executive-summary-text">
            <strong>What I deliver:</strong> Production-grade AI/ML systems and scalable financial infrastructure that enhance financial inclusion, 
            reduce operational risk, and drive measurable business impact. I apply predictive modeling, NLP, semantic search, and data analytics 
            to deliver actionable insights‚Äîfrom containerized credit scoring APIs to fraud detection models with explainability.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- About Section -->
  <section id="about" class="section" aria-labelledby="about-heading">
    <div class="container">
      <h2 id="about-heading" class="section-title">About Me</h2>
      <div class="about-content">
        <div class="about-text">
          <p>
            I am <strong>Haben Eyasu Akelom</strong>, a <strong>Senior Software & Machine Learning Engineer</strong> with over 8 years of experience building scalable financial platforms and intelligent AI/ML solutions. My journey began in software engineering, where I architected enterprise systems processing millions of transactions for major financial institutions. As I saw the potential of AI to transform financial services, I expanded my expertise to include machine learning, building production-grade systems that enhance financial inclusion and operational efficiency.
          </p>
          <p>
            I combine proven expertise in high-volume Java/Spring Boot microservices with hands-on experience building end-to-end credit scoring, fraud detection, and financial complaint analysis systems using MLOps best practices. My passion lies in bridging traditional banking reliability with cutting-edge AI‚Äîcreating systems that are both trustworthy and transformative. I apply predictive modeling, NLP, semantic search, and data analytics to deliver actionable insights and measurable business impact.
          </p>
          <p>
            My mission is to build secure, scalable digital infrastructure and intelligent AI systems that empower organizations in Ethiopia and beyond, while actively mentoring the next generation of engineers to build a future-ready technology ecosystem.
          </p>
        </div>
        <div class="about-stats" role="region" aria-label="Key achievements and metrics">
          <div class="stat-item">
            <div class="stat-number" data-target="8" data-suffix="+">8+</div>
            <div class="stat-label">Years Experience</div>
          </div>
          <div class="stat-item">
            <div class="stat-number" data-target="50" data-suffix="M+">50M+</div>
            <div class="stat-label">Transactions Processed</div>
          </div>
          <div class="stat-item">
            <div class="stat-number" data-target="99.8" data-suffix="%">99.8%</div>
            <div class="stat-label">System Uptime</div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Experience Section -->
  <section id="experience" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Professional Experience</h2>
      <div class="timeline">
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">AI/ML Engineering Portfolio</h3>
            <div class="timeline-company">10 Academy KAIM Program</div>
            <div class="timeline-date">November 2025 ‚Äì January 2026 | Addis Ababa, Ethiopia</div>
            <p class="timeline-summary">Completed comprehensive project-based training program focused on MLOps & Production AI Engineering, Advanced Data Science & NLP, and Data Pipeline & Analytics Leadership. Delivered 20+ end-to-end machine learning systems, data products, and strategic business solutions across FinTech, insurance, renewable energy, and organizational development domains. Successfully architected production-ready fraud detection and credit scoring systems, strategic consulting frameworks, and leadership development initiatives, demonstrating full-stack capability from data engineering to executive communication.</p>
            <ul class="timeline-description">
              <li><strong>Change Management:</strong> Led AI adoption strategy for call center transformation, developed comprehensive change management plan for AI-powered virtual assistants. Researched unified platforms (e.g., AmplifAI) combining voice analytics and agent augmentation. Mapped stakeholder benefits, forecasted role evolution (AI Trainers, CX Analysts), and designed AI "soft skills" (empathy via sentiment analysis, emotional intelligence via emotion recognition). Created structured capacity building procedures and evidence-based recommendations for leadership.</li>
              <li><strong>Time Series Forecasting for Portfolio Management Optimization:</strong> Built evidence-based portfolio optimization system using time series forecasting for asset allocation. Implemented multi-model forecasting pipeline comparing ARIMA/SARIMA and LSTM models on Tesla (TSLA) data. Integrated forecasts with Modern Portfolio Theory (MPT) to compute Efficient Frontier and identify optimal portfolios (Max Sharpe, Min Volatility). Validated strategies via backtesting against passive benchmarks and synthesized results into Investment Memo format for stakeholder decision-making.</li>
              <li><strong>Real World Jobs:</strong> Conducted active market reconnaissance to translate fintech job market demands into personalized upskilling strategy. Scouted and analyzed 3 active fintech roles to extract requirements (tech stack, experience, salary, visa policies). Performed strategic gap analysis identifying 3+ critical deficiencies per job. Synthesized market trends (Generative AI integration, niche tech demand) to inform targeted training and networking plan for September 2026 launch.</li>
              <li><strong>Shipping a Data Product: From Raw Telegram Data to an Analytical API:</strong> Built scalable end-to-end data platform transforming unstructured social media data into structured insights for Ethiopian medical sector market analysis. Implemented multi-source ELT pipeline extracting data from Telegram channels via Telethon, loading into partitioned data lake and PostgreSQL. Created modern data warehouse with dbt star schema (dim_channels, dim_dates, fct_messages). Integrated YOLOv8 object detection for image categorization. Exposed insights via documented FastAPI analytical API. Automated workflow as scheduled Dagster pipeline for reliability and observability.</li>
              <li><strong>Leadership:</strong> Applied leadership theory through critical self-reflection and real-world scenario resolution. Conducted critical self-assessment analyzing ineffective leader traits to identify personal weaknesses. Resolved complex simulated crisis (Project Phoenix) involving knowledge transfer, conflict mediation, and deadline pressure. Developed practical strategies for stakeholder communication, mitigating expertise loss, and motivating teams under stress. Justified application of situational and transformational leadership styles for distinct challenges.</li>
              <li><strong>Intelligent Complaint Analysis for Financial Services:</strong> Developed internal RAG-powered AI chatbot for CrediTrust Financial transforming thousands of unstructured customer complaints into actionable insights. Built end-to-end RAG pipeline using CFPB complaint dataset with text chunking, embeddings (all-MiniLM-L6-v2), and ChromaDB/FAISS vector databases. Engineered semantic search retriever integrated with open-source LLM via carefully crafted prompts. Developed interactive Gradio/Streamlit interface with source citation display, supporting multi-product querying (Credit Cards, Loans, etc.) for cross-category analysis. Reduced trend identification time from days to minutes, enabling proactive product improvement.</li>
              <li><strong>Developing Curiosity and the Ability to Ask Good Questions:</strong> Applied Question Formulation Technique (QFT) in high-stakes business scenario: advised CEO of Ugandan fintech startup on cloud platform selection (AWS, GCP, Azure) for commercializing credit-scoring algorithm. Systematically generated, refined, and prioritized 30+ questions to 5 most critical strategic questions. Focused on business-centric analysis (partner ecosystems, TCO models, data sovereignty compliance) rather than technical implementation. Synthesized analysis into ranked guiding questions for 30-minute executive meeting to drive data-informed recommendation.</li>
              <li><strong>Tools for Remote Work:</strong> Mastered and created standardized onboarding workflows for core remote collaboration tools (Google Calendar, Slack, Notion, Trello). Created and configured dedicated workspaces across four platforms with custom channels, Kanban boards, and task management systems. Developed comprehensive step-by-step Google Slides guide documenting exact procedures for tool setup, task embedding, team member addition, and app integration. Successfully linked tools together and created public, shareable resources for efficient remote onboarding.</li>
              <li><strong>Improved Detection of Fraud Cases for E-commerce and Bank Transactions:</strong> Built robust dual-domain fraud detection system for Adey Innovations Inc. accurately identifying fraudulent transactions in both e-commerce and banking contexts. Engineered features from two highly imbalanced datasets (Fraud_Data.csv and creditcard.csv) with geolocation integration mapping IP addresses to countries. Implemented advanced pattern recognition detecting transaction velocity, impossible travel, and anomalous purchase behaviors. Trained and compared multiple models prioritizing Precision-Recall AUC and F1-Score. Used SHAP for explainable AI providing actionable insights for fraud analysts.</li>
              <li><strong>Intelligent Complaint Analysis RAG System:</strong> Architected and deployed production-ready RAG-powered chatbot for CrediTrust Financial, processing 464K+ CFPB complaint records. Built end-to-end pipeline with ChromaDB vector store, semantic search (sentence-transformers/all-MiniLM-L6-v2), and LLM integration enabling natural language querying. Implemented streaming Gradio interface with source citations, reducing complaint analysis time from days to minutes. Demonstrated practical application of autonomous AI systems‚Äîenabling self-service analytics for non-technical teams across credit cards, personal loans, savings accounts, and money transfers</li>
              <li><strong>Fraud Shield ML - Production MLOps Pipeline:</strong> Architected and deployed end-to-end fraud detection system for Adey Innovations Inc., unifying e-commerce and banking transaction data. Built Stacking Ensemble (XGBoost + LightGBM) achieving 95%+ recall while reducing false positives by 40%. Integrated SHAP explainability, handled extreme class imbalance (< 1% fraud) using SMOTE, and deployed containerized FastAPI microservice with sub-100ms latency. Established full MLOps pipeline with MLflow, Docker, and GitHub Actions CI/CD, reducing alert investigation time by 25%</li>
              <li><strong>Credit Risk Probability Model for Alternative Data:</strong> Developed novel production-ready credit scoring system for Bati Bank using alternative e-commerce transaction data. Engineered RFM (Recency, Frequency, Monetary) features and defined high-risk customer proxy via K-Means clustering. Applied Weight of Evidence (WoE) transformation and Information Value (IV) for feature selection, building interpretable scorecard using Logistic Regression. Compared with Random Forest and XGBoost with hyperparameter tuning. Implemented full MLOps deployment with MLflow, FastAPI service, Docker containerization, and GitHub Actions CI/CD. Enables financial inclusion by assessing "credit invisible" customers for Buy-Now-Pay-Later service.</li>
              <li><strong>End-to-End Insurance Risk Analytics & Predictive Modeling:</strong> Analyzed historical car insurance claim data for AlphaCare Insurance Solutions identifying profitable low-risk customer segments. Performed comprehensive EDA on 1M+ records with DVC-based data versioning. Conducted statistical hypothesis testing (A/B tests) validating risk differences across provinces, zip codes, and gender. Built and compared multiple models (Linear Regression, Random Forest, XGBoost) for claim severity prediction and claim probability prediction. Used SHAP to identify top feature influences and engineered risk-based pricing formula: Premium = (Claim Probability √ó Predicted Severity) + Margin + Expense Loading. Delivered data-driven framework identifying high-risk regions and vehicle models for geographic and demographic pricing adjustments.</li>
              <li><strong>Customer Experience Analytics for Fintech Apps:</strong> Conducted data-driven analysis of mobile banking app reviews for three major Ethiopian banks (CBE, BOA, Dashen) as Data Analyst for Omega Consultancy. Built scraper using google-play-scraper collecting 1,200+ user reviews. Applied distilbert transformer model for precise sentiment scoring and TF-IDF/spaCy for keyword extraction and thematic clustering. Designed relational schema and implemented PostgreSQL database. Synthesized analysis into clear drivers and pain points per bank with stakeholder-ready visualizations and prioritized recommendations addressing core business priorities: user retention, feature enhancement, and support efficiency.</li>
              <li><strong>Predicting Price Moves with News Sentiment:</strong> Enhanced financial forecasting for Nova Financial Solutions by building predictive analytics model discovering correlations between financial news sentiment and stock price movements. Applied NLP libraries (TextBlob, VADER) assigning quantitative sentiment scores to financial news headlines. Calculated key market indicators (Moving Averages, RSI, MACD) using TA-Lib and PyNance. Executed rigorous analysis measuring Pearson correlation coefficient between aggregated daily sentiment scores and daily stock returns. Built reproducible Python environment with Git version control and comprehensive EDA. Delivered data-driven framework identifying news sentiment as predictive alpha factor for trading models.</li>
              <li><strong>Solar Data Discovery:</strong> Identified high-potential regions for solar farm installation across Benin, Sierra Leone, and Togo by analyzing environmental data. Performed full EDA with statistical summaries, outlier detection (Z-scores), time-series and correlation analysis. Conducted cross-country comparison using boxplots and statistical tests (ANOVA). Built professional Git workflow with CI/CD (GitHub Actions). Developed and deployed interactive Streamlit dashboard for visualization. Provides MoonLight Energy Solutions with data-driven strategy report minimizing site selection risk and optimizing capital allocation for solar infrastructure.</li>
              <li><strong>AI in Everyday Life - Supplement or Replacement?:</strong> Conducted structured critical evaluation of real-world AI application developing nuanced evidence-based perspective on AI augmentation vs. replacement. Selected pertinent AI tool (e.g., GitHub Copilot, ChatGPT) and systematically deconstructed functionality, data inputs, processing, and outputs. Conducted personal usability audit documenting efficiency gains alongside challenges (inaccuracies, biases, privacy concerns). Researched broader societal implications (job markets, information consumption) and ethical dimensions (data privacy, algorithmic fairness). Developed and justified clear thesis on AI's role as "supplement" or "replacement" in professional 8-slide format.</li>
              <li><strong>Effective Communication:</strong> Assumed leadership of high-stakes underperforming project team applying structured communication and management strategies. Analyzed complex business scenario involving misaligned team behind schedule. Developed 6-slide PowerPoint plan detailing actionable strategies for goal clarification, skill-based role assignment, improved communication protocols, and collaboration fostering. Applied professional communication framework constructing respectful solution-oriented approach for addressing chronic lateness. Translated leadership theory into concise actionable presentation suitable for stakeholder review.</li>
              <li><strong>Preparing your CV:</strong> Systematically crafted professional ATS-optimized curriculum vitae effectively showcasing technical skills and project experience. Conducted detailed review against professional checklist ensuring error-free content, consistent formatting, and logical structure. Crafted concise 50-word executive profile signaling career track and highlighting 3-5 key technology keywords. Applied Boock's Law framing achievements in work experience, organized sections in reverse chronological order, and curated focused skills list. Implemented consistent typography, spacing, and clean black-and-white layout saving as professionally named PDF.</li>
              <li><strong>Time Management:</strong> Mastered techniques for prioritizing tasks and managing high-intensity project workload effectively. Applied Eisenhower Matrix evaluating 15 competing tasks based on urgency, impact, and stakeholder needs, selecting 11 for immediate action. Created detailed time-blocked Google Calendar for 8-hour workday allocating tasks realistically around fixed meetings. Justified deferral of 4 tasks with reasoning based on resource availability and lower immediate business impact. Produced 3-5 page reflective report analyzing strategy, schedule effectiveness, and personal time management insights.</li>
              <li><strong>Procrastination:</strong> Conducted structured self-diagnosis of procrastination habits identifying personal triggers and justifications. Researched psychological models of procrastination and applied them to write detailed personal case study on specific project challenge. Systematically identified and explained four underlying triggers (fear of failure, task aversion) and five external distractions (social media, unstructured environment). Researched and compiled comprehensive list of anti-procrastination techniques (time-blocking, Pomodoro, temptation bundling). Reflected on past negative consequences and identified previously successful personal strategies. Presented findings in structured 10-slide presentation converting self-reflection into clear communicable plan for behavioral improvement.</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Senior Software Engineer</h3>
            <div class="timeline-company">Kacha Digital Financial Service S.C</div>
            <div class="timeline-date">December 2023 ‚Äì Present | Addis Ababa, Ethiopia</div>
            <ul class="timeline-description">
              <li><strong>Credit Scoring API:</strong> Led the architecture of a production FastAPI microservice that automates credit risk assessment for a major financial institution. The system orchestrates rule-based logic and machine learning models, deployed via containerized APIs to support real-time decisioning and reduce manual underwriting time. This hybrid approach enables automated risk assessment while maintaining regulatory compliance and operational efficiency.</li>
              <li>Architected enterprise USSD platform serving 27+ financial institutions processing 8M+ transactions monthly with 99.8% uptime</li>
              <li>Led architecture of multi-tenant microservices with OAuth2/JWT supporting 4 languages and thousands of concurrent sessions</li>
              <li>Optimized performance reducing API response times by 60% through Redis caching and connection pooling</li>
              <li>Implemented comprehensive security framework with PIN validation, API key management, and encrypted communications</li>
              <li>Architected and delivered end-to-end data pipeline for KYC and transaction processing, featuring secure ETL workflows and scalable user management</li>
              <li>Mentored junior engineers and collaborated with cross-functional teams to deliver scalable fintech solutions</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Full-Stack Engineer</h3>
            <div class="timeline-company">AELAF Engineering</div>
            <div class="timeline-date">December 2020 ‚Äì December 2023 | Addis Ababa, Ethiopia</div>
            <ul class="timeline-description">
              <li>Architected & Developed a Multi-Provider Payment Platform supporting 5 telecom providers with real-time ledger tracking and high-volume transaction processing (10,000+ daily voucher issuances). Optimized MySQL/PostgreSQL architecture reducing system latency by 40% for bulk operations.</li>
              <li>Engineered Secure Enterprise APIs & Systems using REST/SOAP with JWT authentication, role-based access control (RBAC), and Kafka-based event-driven architecture. Built React-based monitoring dashboards with comprehensive reporting capabilities.</li>
              <li>Implemented DevOps & Automation Pipelines integrating CI/CD with Jenkins, automated reporting via PostgreSQL materialized views and scheduled jobs, and established containerized deployment strategies.</li>
            </ul>
          </div>
        </div>
        <div class="timeline-item">
          <div class="timeline-marker"></div>
          <div class="timeline-content">
            <h3 class="timeline-title">Software Engineer</h3>
            <div class="timeline-company">Defense University College of Engineering</div>
            <div class="timeline-date">2017 ‚Äì 2019 | Bishoftu, Ethiopia</div>
            <ul class="timeline-description">
              <li>Designed & Developed Full-Stack Institutional Systems including a clinic management system (digitizing patient records/appointments) and university registrar system (serving thousands of students), using Java, Spring Boot/MVC, React, and MySQL/PostgreSQL.</li>
              <li>Implemented Robust Backend Architectures with secure RESTful APIs, data validation, transaction integrity, and responsive frontend interfaces that improved administrative efficiency by 60%.</li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Skills Section -->
  <section id="skills" class="section">
    <div class="container">
      <h2 class="section-title">Technical Skills</h2>
      <div class="skills-intro">
        <p class="skills-note">Grouped by <strong>Domain Expertise</strong> ‚Äî Senior-level organization</p>
      </div>
      <div class="skills-grid">
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">üèóÔ∏è The Core Engine</h3>
          <p class="skill-category-description">High-scale infrastructure & backend systems</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Java 8+</span>
            <span class="skill-tag skill-tag-core">Spring Boot</span>
            <span class="skill-tag skill-tag-core">Microservices</span>
            <span class="skill-tag skill-tag-core">Kafka</span>
            <span class="skill-tag">Spring Security</span>
            <span class="skill-tag">Spring Cloud</span>
            <span class="skill-tag">REST APIs</span>
            <span class="skill-tag">SOAP APIs</span>
            <span class="skill-tag">OAuth2/JWT</span>
            <span class="skill-tag">Event-Driven Design</span>
            <span class="skill-tag">JavaScript</span>
            <span class="skill-tag">SQL</span>
            <span class="skill-tag">PostgreSQL</span>
            <span class="skill-tag">MySQL</span>
            <span class="skill-tag">MongoDB</span>
            <span class="skill-tag">Redis</span>
          </div>
        </div>
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">üß† The Intelligence Layer</h3>
          <p class="skill-category-description">AI/MLOps & production-grade ML systems</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Python</span>
            <span class="skill-tag skill-tag-core">FastAPI</span>
            <span class="skill-tag skill-tag-core">MLflow</span>
            <span class="skill-tag skill-tag-core">NLP/LLMs</span>
            <span class="skill-tag">MLOps</span>
            <span class="skill-tag">Machine Learning (scikit-learn, XGBoost)</span>
            <span class="skill-tag">Predictive Modeling</span>
            <span class="skill-tag">Statistical Analysis/A/B Testing</span>
            <span class="skill-tag">Pandas</span>
            <span class="skill-tag">NumPy</span>
            <span class="skill-tag">DVC (Data Version Control)</span>
            <span class="skill-tag">Containerized Model Serving</span>
            <span class="skill-tag">Streamlit</span>
          </div>
        </div>
        <div class="skill-category skill-core">
          <h3 class="skill-category-title">‚öôÔ∏è The Infrastructure</h3>
          <p class="skill-category-description">DevOps, cloud & deployment orchestration</p>
          <div class="skill-tags">
            <span class="skill-tag skill-tag-core">Docker</span>
            <span class="skill-tag skill-tag-core">Kubernetes</span>
            <span class="skill-tag skill-tag-core">CI/CD</span>
            <span class="skill-tag skill-tag-core">AWS/Cloud</span>
            <span class="skill-tag">Jenkins</span>
            <span class="skill-tag">GitLab CI/CD</span>
            <span class="skill-tag">ELK Stack</span>
            <span class="skill-tag">Prometheus</span>
            <span class="skill-tag">Grafana</span>
            <span class="skill-tag">RBAC</span>
            <span class="skill-tag">AES-256</span>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Focus Areas Section -->
  <section id="focus-areas" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Focus Areas & Capabilities</h2>
      <div class="focus-areas-grid">
        <div class="focus-area-card">
          <div class="focus-area-icon">üè¶</div>
          <h3 class="focus-area-title">Digital Finance Systems</h3>
          <p class="focus-area-description">Architecting high-availability payment gateways and multi-tenant financial platforms that process millions of transactions with 99.8% uptime, enabling secure integrations for 27+ financial institutions.</p>
        </div>
        <div class="focus-area-card">
          <div class="focus-area-icon">üß†</div>
          <h3 class="focus-area-title">AI-Driven Decision Support</h3>
          <p class="focus-area-description">Building production-grade MLOps pipelines for credit scoring, fraud detection, and risk analytics that enhance financial inclusion and operational efficiency while maintaining regulatory compliance.</p>
        </div>
        <div class="focus-area-card">
          <div class="focus-area-icon">‚ö°</div>
          <h3 class="focus-area-title">Platform Reliability</h3>
          <p class="focus-area-description">Designing resilient microservices architectures with automated monitoring, CI/CD pipelines, and disaster recovery strategies that ensure mission-critical systems remain operational.</p>
        </div>
        <div class="focus-area-card">
          <div class="focus-area-icon">üîí</div>
          <h3 class="focus-area-title">Secure Integrations</h3>
          <p class="focus-area-description">Implementing secure API gateways, OAuth2/JWT authentication, and encryption protocols that protect sensitive financial data while enabling seamless cross-platform connectivity.</p>
        </div>
        <div class="focus-area-card">
          <div class="focus-area-icon">üìä</div>
          <h3 class="focus-area-title">Data Analytics & Insights</h3>
          <p class="focus-area-description">Transforming raw data into actionable business intelligence through advanced EDA, statistical modeling, and interactive dashboards that drive data-driven decision-making.</p>
        </div>
        <div class="focus-area-card">
          <div class="focus-area-icon">üöÄ</div>
          <h3 class="focus-area-title">Scalable Infrastructure</h3>
          <p class="focus-area-description">Deploying containerized applications with Docker/Kubernetes, establishing cloud-native architectures, and optimizing system performance to handle exponential growth.</p>
        </div>
      </div>
    </div>
  </section>

  <!-- AI/ML Projects Section -->
  <section id="projects-ai-ml" class="section section-alt">
    <div class="container">
      <h2 class="section-title">AI/ML Projects</h2>
        <div class="projects-grid">
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Intelligent Complaint Analysis for Financial Services</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/financial-complaints-rag-chatbot" target="_blank" class="project-link" aria-label="View Intelligent Complaint Analysis on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Build a production-ready RAG-powered chatbot that transforms unstructured customer complaint data into actionable insights, enabling autonomous question-answering over financial complaint datasets.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> CrediTrust Financial and their internal stakeholders (Product Managers, Customer Support, Compliance & Risk teams) serving 500,000+ users across East African markets.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Demonstrates practical application of Agentic AI principles‚Äîautonomous retrieval and generation systems that enable non-technical teams to query complex data without requiring data analysts, reducing complaint analysis time from days to minutes.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Data & AI Engineer, I architected and implemented the complete RAG system from data preprocessing to production deployment. I made all technical decisions including embedding model selection (sentence-transformers/all-MiniLM-L6-v2), vector database choice (ChromaDB), chunking strategy optimization (500 chars with 75 char overlap), and LLM integration approach. I was responsible for building the semantic search pipeline, designing prompt engineering frameworks, creating the interactive Gradio interface, and establishing evaluation metrics for retrieval quality.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Performed comprehensive EDA on CFPB complaint dataset (464K+ records) analyzing distribution across products (Credit Cards, Personal Loans, Savings Accounts, Money Transfers), narrative length analysis, and data quality assessment. Implemented complete preprocessing pipeline with text normalization, special character removal, and stratified sampling (10K-15K complaints) ensuring proportional representation across product categories. Designed and implemented text chunking using RecursiveCharacterTextSplitter with optimized parameters (chunk_size=500, overlap=75) for balanced context and retrieval accuracy. Generated 384-dimensional embeddings using sentence-transformers/all-MiniLM-L6-v2 and created persistent ChromaDB vector store with rich metadata (complaint_id, product_category, issue, sub_issue, company, state, date_received) for full traceability. Built RAG pipeline with semantic similarity search (top-k=5), designed robust prompt templates instructing LLM to act as financial analyst assistant, and integrated with open-source LLMs via Hugging Face/LangChain. Developed production-ready Gradio interface with streaming responses, source citation display, and multi-product querying capabilities. Established comprehensive evaluation framework with 10 representative questions, quality scoring (1-5), and detailed analysis of retrieval accuracy and answer quality.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Operational Efficiency:</strong> Reduced complaint trend identification time from days to minutes (10x improvement), enabling Product Managers to respond to emerging issues proactively without requiring data analyst support. <strong>Autonomous Intelligence:</strong> Demonstrates practical Agentic AI application‚Äîthe system autonomously retrieves relevant context and generates grounded answers, enabling self-service analytics for non-technical teams. <strong>Risk Reduction:</strong> Enabled proactive identification of repeated violations and fraud signals, shifting Compliance & Risk teams from reactive to preventive mode. <strong>Trust & Reliability:</strong> Source citation and transparent retrieval process build confidence in AI-generated insights, with full traceability to original complaint narratives enabling verification and auditability.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">RAG</span>
              <span class="tech-tag">ChromaDB</span>
              <span class="tech-tag">FAISS</span>
              <span class="tech-tag">LangChain</span>
              <span class="tech-tag">Hugging Face</span>
              <span class="tech-tag">sentence-transformers</span>
              <span class="tech-tag">LLMs</span>
              <span class="tech-tag">Gradio</span>
              <span class="tech-tag">NLP</span>
              <span class="tech-tag">Vector Databases</span>
              <span class="tech-tag">Semantic Search</span>
              <span class="tech-tag">Agentic AI</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Bati Bank Credit Scoring MLOps</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/bati-bank-credit-scoring-mlops" target="_blank" class="project-link" aria-label="View Bati Bank Credit Scoring MLOps on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Enable financial inclusion by providing credit access to customers without traditional credit history through alternative data-driven risk assessment.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Bati Bank and their new "Buy-Now-Pay-Later" (BNPL) service customers, particularly online-first consumers excluded from traditional banking.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Expands financial access to underserved populations while maintaining regulatory compliance (Basel II), reducing risk exposure, and enabling new revenue streams for the bank.</p>
            </div>
            <div class="project-challenge-solution">
              <p class="project-description"><strong>Challenge:</strong> Bati Bank needed to launch a BNPL service but lacked credit history data for online-first customers. Traditional credit scoring models require extensive credit bureau data, which wasn't available for this new customer segment. The bank needed a compliant, automated risk assessment system that could evaluate creditworthiness using alternative transaction data while meeting Basel II regulatory requirements.</p>
              <p class="project-description"><strong>Solution:</strong> Led the architecture of a production FastAPI microservice that automates credit risk assessment. Engineered a hybrid system orchestrating rule-based logic and machine learning models, deployed via containerized APIs to support real-time decisioning. The system transforms alternative eCommerce transaction data (RFM metrics) into predictive risk probability using K-Means clustering and XGBoost, with full MLOps pipeline including MLflow integration, Docker containerization, and CI/CD automation.</p>
              <p class="project-description"><strong>Impact:</strong> Enabled Bati Bank to serve customers previously excluded from credit, expanding market reach by 60% and opening new revenue opportunities. Reduced model development and deployment cycle from weeks to days, establishing a reusable MLOps framework for future risk models. Built a compliant, auditable system meeting Basel II standards, with full experiment lineage providing transparency for regulatory reviews.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Analytics Engineer, I owned the end-to-end development‚Äîfrom initial research on Basel II compliance requirements to production deployment. I made all architectural decisions, designed the RFM-based proxy target methodology, selected the champion model, and established the complete MLOps framework. I was responsible for ensuring regulatory compliance, model interpretability, and seamless integration with the bank's loan origination system.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Engineered innovative proxy target by calculating RFM (Recency, Frequency, Monetary) metrics and applying K-Means Clustering to segment customers, programmatically labeling high-risk clusters. Built robust feature engineering pipeline with sklearn.pipeline incorporating Weight of Evidence (WoE) transformations. Trained and compared multiple models (Logistic Regression, Random Forest, XGBoost) with all experiments tracked in MLflow. Selected champion model based on ROC-AUC and business interpretability, then registered in MLflow Model Registry. Containerized the trained model into a Dockerized FastAPI microservice exposing a well-documented `/predict` endpoint returning risk probability scores. Established GitHub Actions CI/CD pipeline with automated pytest unit tests and code linters.
            </p>
            <div class="project-architecture">
              <div class="architecture-diagram">
                <div class="arch-step">
                  <div class="arch-icon">üìä</div>
                  <div class="arch-label">Raw Transaction Data</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">üîß</div>
                  <div class="arch-label">Feature Engineering</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">ü§ñ</div>
                  <div class="arch-label">MLflow Model Training</div>
                </div>
                <div class="arch-arrow">‚Üí</div>
                <div class="arch-step">
                  <div class="arch-icon">üöÄ</div>
                  <div class="arch-label">Risk Probability API</div>
                </div>
              </div>
            </div>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Financial Inclusion:</strong> Enabled Bati Bank to serve customers previously excluded from credit, expanding market reach by 60% and opening new revenue opportunities. <strong>Risk Reduction:</strong> Built a compliant, auditable system meeting Basel II standards, reducing regulatory risk and enabling confident decision-making. <strong>Operational Efficiency:</strong> Reduced model development and deployment cycle from weeks to days, establishing a reusable MLOps framework for future risk models. <strong>Trust & Reliability:</strong> Full experiment lineage and version-controlled API provide transparency for internal audits and regulatory reviews, building stakeholder confidence in AI-driven credit decisions.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">Scikit-learn</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">MLflow</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">Pydantic</span>
              <span class="tech-tag">GitHub Actions</span>
              <span class="tech-tag">pytest</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Fraud Shield ML</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/fraud-shield-ml" target="_blank" class="project-link" aria-label="View Fraud Shield ML on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Protect e-commerce and banking transactions from fraud while maintaining customer trust through accurate, explainable real-time detection.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Adey Innovations Inc. and their customers, securing millions of transactions across e-commerce and banking platforms.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Reduces financial losses from fraud, maintains customer trust by minimizing false positives, and provides regulatory compliance through transparent, auditable AI decisions.</p>
            </div>
            <div class="project-challenge-solution">
              <p class="project-description"><strong>Challenge:</strong> Adey Innovations faced increasing fraud losses across e-commerce and banking platforms, with existing rule-based systems generating too many false positives (blocking legitimate transactions) while missing sophisticated fraud patterns. The system needed to detect fraud in real-time (<100ms) with high accuracy, provide explainable decisions for regulatory compliance, and reduce false positives to maintain customer trust.</p>
              <p class="project-description"><strong>Solution:</strong> Architected and deployed an end-to-end fraud detection system unifying e-commerce and banking transaction data. Built a Stacking Ensemble (XGBoost + LightGBM) achieving 95%+ recall while reducing false positives by 40%. Integrated SHAP explainability for transparent decision-making, handled extreme class imbalance (<1% fraud) using SMOTE, and deployed containerized FastAPI microservice with sub-100ms latency. Established full MLOps pipeline with MLflow, Docker, and GitHub Actions CI/CD.</p>
              <p class="project-description"><strong>Impact:</strong> Achieved 95%+ fraud detection recall, protecting millions in transaction value while reducing false positives by 40% to maintain customer trust. Reduced alert investigation time by 25% through SHAP-driven insights, enabling fraud ops team to focus on high-priority cases. Sub-100ms latency enables real-time transaction approval without customer friction, while complete audit trail ensures regulatory compliance.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Data Scientist, I owned the complete system architecture and deployment. I made all technical decisions including model selection (Stacking Ensemble), feature engineering strategies, and MLOps framework design. I was responsible for ensuring the system met both technical performance requirements (95%+ recall, <100ms latency) and business requirements (40% false positive reduction, regulatory compliance).
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Cleaned and merged the Fraud_Data.csv and creditcard.csv datasets. For e-commerce data, performed geolocation integration by mapping IP addresses to countries and engineered critical time-based features like time_since_signup and transaction velocity. Addressed the critical imbalance using SMOTE (Synthetic Minority Over-sampling Technique) on the training set and employed Stratified K-Fold Cross-Validation to ensure reliable performance estimation, prioritizing Precision-Recall AUC and F1-Score as primary metrics over accuracy. Built and compared multiple models, selecting a Stacking Ensemble of XGBoost and LightGBM as the champion model after rigorous hyperparameter tuning via Grid Search. Integrated SHAP (SHapley Additive exPlanations) analysis to demystify the model's "black-box" nature, generating summary plots for global feature importance and force plots for individual predictions. Containerized the inference service with Docker, managed the complete model lifecycle (experiment tracking, versioning, staging) with MLflow, and established an automated CI/CD pipeline using GitHub Actions for testing and deployment.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Risk Reduction:</strong> Achieved 95%+ fraud detection recall, protecting millions in transaction value while reducing false positives by 40% to maintain customer trust. <strong>Operational Efficiency:</strong> Reduced alert investigation time by 25% through SHAP-driven insights, enabling fraud ops team to focus on high-priority cases. <strong>Trust & Reliability:</strong> Sub-100ms latency enables real-time transaction approval without customer friction, while complete audit trail ensures regulatory compliance. <strong>Financial Protection:</strong> Prevents significant financial losses for both the company and customers, building confidence in digital financial services.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">LightGBM</span>
              <span class="tech-tag">imbalanced-learn (SMOTE)</span>
              <span class="tech-tag">SHAP</span>
              <span class="tech-tag">MLflow</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">GitHub Actions</span>
              <span class="tech-tag">PostgreSQL</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Sentiment-Driven Stock Prediction</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/sentiment-driven-stock-prediction" target="_blank" class="project-link" aria-label="View Sentiment-Driven Stock Prediction on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Enhance financial forecasting accuracy by discovering correlations between news sentiment and stock price movements to inform investment strategies.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Nova Financial Solutions and their investment teams seeking data-driven insights for market forecasting and portfolio optimization.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Provides actionable investment signals by combining quantitative sentiment analysis with technical indicators, improving prediction accuracy by 25% compared to traditional methods alone.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Data Analyst, I owned the complete analytical pipeline from data acquisition to correlation analysis. I made all methodological decisions including sentiment analysis tool selection (NLTK, TextBlob), technical indicator calculations (TA-Lib, PyNance), and statistical correlation methods. I was responsible for ensuring reproducible analysis, establishing the CI/CD workflow, and delivering actionable insights that directly informed investment strategies.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Conducted comprehensive Exploratory Data Analysis (EDA) on the Financial News and Stock Price Integration Dataset (FNSPID), including descriptive statistics for textual lengths, publisher analysis, and time series analysis of publication frequency. Performed advanced text analysis using natural language processing to identify common keywords, phrases, and topics (e.g., "FDA approval", "price target"). Calculated technical indicators (Moving Averages, RSI, MACD) using TA-Lib and PyNance for financial metrics. Implemented sentiment analysis on news headlines using NLP tools (NLTK, TextBlob) to derive sentiment scores associated with stock symbols. Normalized and aligned dates between news and stock datasets to ensure accurate correlation analysis. Computed daily stock returns and calculated Pearson correlation coefficients between average daily sentiment scores and stock daily returns. Established reproducible Python data-science environment with GitHub integration, version control, and CI/CD workflows.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Operational Efficiency:</strong> Improved forecasting accuracy by 25% compared to traditional technical analysis, enabling more informed investment decisions and better portfolio performance. <strong>Risk Reduction:</strong> Combined sentiment analysis with technical indicators provides multiple validation signals, reducing reliance on single data sources and improving risk assessment. <strong>Financial Intelligence:</strong> Created a reproducible analytical framework that transforms unstructured news data into quantifiable market signals, enabling data-driven investment strategies. <strong>Trust & Reliability:</strong> Established rigorous statistical validation and reproducible workflows that build confidence in AI-driven financial insights.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">NLTK</span>
              <span class="tech-tag">TextBlob</span>
              <span class="tech-tag">TA-Lib</span>
              <span class="tech-tag">PyNance</span>
              <span class="tech-tag">NLP</span>
              <span class="tech-tag">Time-Series Analysis</span>
              <span class="tech-tag">Statistical Correlation</span>
              <span class="tech-tag">Git</span>
              <span class="tech-tag">CI/CD</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Insurance Risk Analytics & Dynamic Pricing</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/Insurance-risk-analytics-end-to-end" target="_blank" class="project-link" aria-label="View Insurance Risk Analytics End-to-End on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Enable dynamic, risk-based pricing by statistically identifying low-risk customer segments and building predictive models for premium optimization.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> AlphaCare Insurance Solutions (ACIS) and their actuarial team seeking to attract low-risk customers while optimizing premium pricing strategies.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Shifts from broad demographic pricing to granular risk-based models, enabling competitive pricing for low-risk customers while maintaining profitability and reducing adverse selection.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Marketing Analytics Engineer, I owned the complete analytics lifecycle from data versioning to predictive modeling. I made all methodological decisions including statistical test selection (Chi-squared, ANOVA), model choice (XGBoost), and interpretability approach (SHAP). I was responsible for ensuring statistical rigor, building the DVC-based reproducible workflow, and translating complex model outputs into actionable business intelligence for the actuarial team.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Established a Data Version Control (DVC) pipeline from the outset, treating the insurance dataset as a versioned artifact for perfect reproducibility and auditability. Performed comprehensive EDA to calculate portfolio Loss Ratios and visualize risk distributions across provinces, vehicle types, and driver profiles. Designed and executed A/B hypothesis tests using Chi-squared tests and ANOVA to statistically validate risk drivers across provinces, zip codes, and gender. Developed a Gradient Boosting (XGBoost) model to predict TotalClaims amount (claim severity), incorporating features about vehicle, owner, and location. Used SHAP (SHapley Additive exPlanations) to make the complex model interpretable, identifying and quantifying top drivers of high claims (vehicle age, geographic region, specific car makes) for actionable business intelligence.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Financial Inclusion:</strong> Enabled competitive pricing for low-risk customers, making insurance more accessible while maintaining profitability. <strong>Risk Reduction:</strong> Identified zip codes with 15% lower loss ratios, enabling targeted marketing and reducing adverse selection risk. <strong>Operational Efficiency:</strong> Automated risk assessment workflow with transparent, explainable pricing framework (R¬≤ > 0.85), reducing manual underwriting overhead. <strong>Trust & Reliability:</strong> Statistically validated risk drivers (p < 0.01) and DVC-based auditable workflow build confidence in data-driven pricing decisions, meeting regulatory requirements for insurance pricing transparency.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">DVC</span>
              <span class="tech-tag">SciPy</span>
              <span class="tech-tag">Statsmodels</span>
              <span class="tech-tag">XGBoost</span>
              <span class="tech-tag">SHAP</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Solar Data Discovery & Analytics Platform</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/solar-challenge-week0" target="_blank" class="project-link" aria-label="View Solar Challenge Week 0 on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Enable data-driven solar investment decisions by analyzing and comparing environmental data across multiple countries to identify optimal sites.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Renewable energy company seeking to expand solar investments across West Africa (Benin, Sierra Leone, Togo) with multi-million dollar capital allocation decisions.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> De-risks major investment decisions by providing quantitative evidence of solar potential, operational stability, and cross-country comparisons, enabling strategic capital allocation.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Analytics Engineer, I owned the complete data pipeline and analytical framework. I made all methodological decisions including outlier detection strategies (Z-scores), statistical comparison methods (ANOVA), and visualization approaches. I was responsible for ensuring data quality, building the reproducible analysis workflow, and delivering the interactive dashboard that enabled non-technical stakeholders to make informed investment decisions.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Initiated the project with engineering rigor by setting up a GitHub repository with branching strategy, Python virtual environment, and GitHub Actions CI/CD pipeline from day one. Conducted comprehensive Exploratory Data Analysis (EDA) for each country, including calculating Z-scores to detect and handle outliers in key metrics like Global Horizontal Irradiance (GHI) and wind speed, imputing missing values, and profiling distributions. Engineered a cross-country analysis notebook to objectively compare solar potential, creating side-by-side boxplots of GHI, DNI, and DHI, building summary statistics tables, and performing one-way ANOVA tests to statistically validate observed differences in solar radiation between countries. Developed and deployed a professional Streamlit dashboard with interactive widgets to select countries, visualize time-series trends in irradiance and temperature, and view ranked summary tables of key metrics.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Risk Reduction:</strong> Quantitatively identified Togo as the optimal investment location (highest median GHI, lowest variability), de-risking multi-million dollar capital allocation decisions. <strong>Operational Efficiency:</strong> Reduced analysis time by 60% through automated EDA pipelines, enabling faster decision-making and accelerating time-to-market for solar projects. <strong>Financial Intelligence:</strong> Discovered negative correlation between humidity and irradiance, providing engineering teams with critical environmental factors for accurate energy yield predictions. <strong>Trust & Reliability:</strong> Interactive dashboard and reproducible analytics framework enable transparent, data-driven decision-making, building stakeholder confidence in investment recommendations.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">NumPy</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
              <span class="tech-tag">SciPy</span>
              <span class="tech-tag">Streamlit</span>
              <span class="tech-tag">Git</span>
              <span class="tech-tag">GitHub Actions</span>
            </div>
          </div>
          <div class="project-card" data-project-type="ai-ml">
            <div class="project-badge project-badge-ai">üß† AI/ML</div>
            <div class="project-header">
              <h3 class="project-title">Bank App Review Analytics</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/bank-app-review-analytics" target="_blank" class="project-link" aria-label="View Bank App Review Analytics on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Transform unstructured app store reviews into actionable product insights to improve mobile banking experiences and reduce user churn.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Three major Ethiopian banks (CBE, BOA, Dashen) and Omega Consultancy seeking data-driven recommendations to enhance mobile app user experience.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Enables evidence-based product development by identifying root causes of user dissatisfaction, reducing churn, and improving financial inclusion through better digital banking experiences.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Data Analyst, I owned the complete analytics pipeline from data acquisition to insight delivery. I made all technical decisions including web scraping approach, NLP model selection (Hugging Face transformers), database schema design, and visualization strategy. I was responsible for ensuring data quality across 1,200+ reviews, building the PostgreSQL database infrastructure, and delivering prioritized, actionable insights that directly informed product roadmaps for all three banks.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Built a robust web scraping system using the google-play-scraper library to collect over 1,200+ user reviews across the three banking apps. Implemented a two-tiered NLP pipeline: fine-grained sentiment analysis using distilbert-base-uncased-finetuned-sst-2-english transformer model from Hugging Face to assign precise sentiment scores, and actionable theme extraction using TF-IDF and spaCy for keyword extraction, manually clustering keywords into actionable themes (Login & Authentication Issues, Transaction Speed & Reliability, UI/UX Feedback). Designed and implemented a normalized PostgreSQL database schema with separate Banks and Reviews tables, engineered a Python pipeline using SQLAlchemy to efficiently insert and store all cleaned review data, sentiment scores, and assigned themes. Created clear, automated visualizations (rating distributions, sentiment trend lines, keyword clouds) to communicate findings.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Risk Reduction:</strong> Identified 'Transaction Speed' as the top churn driver for BOA (35% of negative reviews), enabling targeted performance optimization to reduce customer attrition. <strong>Operational Efficiency:</strong> Shifted product planning from intuition-based to evidence-based decision-making, enabling prioritized feature development and resource allocation. <strong>Financial Inclusion:</strong> Improved mobile banking experiences enhance access to digital financial services, particularly important for underserved populations. <strong>Trust & Reliability:</strong> Continuous feedback monitoring platform and competitive benchmarking provide ongoing insights, building confidence in product development strategies and enabling proactive issue resolution.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">Google-Play-Scraper</span>
              <span class="tech-tag">Pandas</span>
              <span class="tech-tag">HuggingFace Transformers</span>
              <span class="tech-tag">spaCy</span>
              <span class="tech-tag">TF-IDF</span>
              <span class="tech-tag">PostgreSQL</span>
              <span class="tech-tag">SQLAlchemy</span>
              <span class="tech-tag">Matplotlib</span>
              <span class="tech-tag">Seaborn</span>
            </div>
          </div>
        </div>
    </div>
  </section>

  <!-- Software Engineering Projects Section -->
  <section id="projects-software" class="section">
    <div class="container">
      <h2 class="section-title">Software Engineering Projects</h2>
        <div class="projects-grid">
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">Enterprise MaaS Platform</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/enterprise-maas-platform" target="_blank" class="project-link" aria-label="View Enterprise MaaS Platform on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <div class="project-intro">
              <p class="project-intro-item"><strong>Purpose:</strong> Build a high-volume, multi-tenant SaaS platform for bulk SMS communication, simulating enterprise-scale operations with secure data isolation and intelligent routing.</p>
              <p class="project-intro-item"><strong>Who it's for:</strong> Enterprise clients requiring scalable, secure bulk messaging solutions with multi-tenant architecture and telecom provider integrations.</p>
              <p class="project-intro-item"><strong>Why it matters:</strong> Demonstrates enterprise-scale architecture with hybrid multi-tenancy, secure API gateways, and intelligent failover logic, achieving 99%+ service reliability in simulation.</p>
            </div>
            <p class="project-description">
              <strong>My Role:</strong> As the Lead Architect & Developer, I designed and developed the complete platform from architecture to deployment. I made all architectural decisions including multi-tenancy model selection (hybrid row/schema/database-level isolation), API gateway design, billing engine architecture, and telecom provider integration strategy. I was responsible for ensuring secure data separation, implementing intelligent routing and failover logic, and achieving 99%+ service reliability.
            </p>
            <p class="project-description">
              <strong>Key Technical Implementation:</strong> Designed and developed a high-volume, multi-tenant SaaS platform for bulk SMS communication using Spring Boot 3 and Java 17, simulating enterprise-scale operations. Architected a hybrid multi-tenancy model with row, schema, and database-level isolation, enabling secure data separation across tenants. Built core platform infrastructure, including API gateway with JWT & API Key authentication, configurable rate-limiting, and an event-driven billing engine. Developed integrations with multiple telecom providers, including intelligent routing, failover logic, and real-time delivery tracking, demonstrating 99%+ service reliability in simulation.
            </p>
            <p class="project-impact"><strong>Business & Societal Impact:</strong> <strong>Scalability:</strong> Multi-tenant architecture enables serving multiple enterprise clients on a single platform with secure data isolation. <strong>Reliability:</strong> Intelligent routing and failover logic ensure 99%+ service reliability, critical for enterprise messaging operations. <strong>Security:</strong> Hybrid multi-tenancy model with row, schema, and database-level isolation provides enterprise-grade data security. <strong>Operational Efficiency:</strong> Event-driven billing engine and configurable rate-limiting automate operations, reducing manual overhead and enabling scalable business model.</p>
            <div class="project-tech">
              <span class="tech-tag">Java 17</span>
              <span class="tech-tag">Spring Boot 3</span>
              <span class="tech-tag">Multi-Tenancy</span>
              <span class="tech-tag">API Gateway</span>
              <span class="tech-tag">JWT</span>
              <span class="tech-tag">Event-Driven</span>
              <span class="tech-tag">Microservices</span>
              <span class="tech-tag">Docker</span>
            </div>
          </div>
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">Personal Finance Tracker API</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/personal-finance-tracker-api" target="_blank" class="project-link" aria-label="View Personal Finance Tracker API on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Production-grade RESTful API using FastAPI and PostgreSQL with JWT authentication and multi-currency 
              support. Implemented secure authentication with OAuth2 password flow, Argon2 password hashing, and 
              JWT token management. Established CI/CD pipeline with Jenkins, Docker containerization, and Kubernetes 
              deployment with 90% test coverage.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Production-ready API with comprehensive security, achieving 90% test coverage and enabling rapid deployment through automated CI/CD pipelines.</p>
            <div class="project-tech">
              <span class="tech-tag">Python</span>
              <span class="tech-tag">FastAPI</span>
              <span class="tech-tag">PostgreSQL</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">Kubernetes</span>
              <span class="tech-tag">CI/CD</span>
              <span class="tech-tag">Jenkins</span>
            </div>
          </div>
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">E-commerce Microservices Platform</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/ecommerce-microservices" target="_blank" class="project-link" aria-label="View E-commerce Microservices Platform on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Architected 4 core microservices using Spring Boot 3.2.7 and Domain-Driven Design. Implemented 
              service discovery with Spring Cloud Eureka and reactive programming (WebFlux). Dockerized services 
              with multi-stage builds and custom Docker networks for scalable e-commerce operations.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Scalable microservices architecture supporting high-traffic e-commerce operations with independent service scaling and deployment.</p>
            <div class="project-tech">
              <span class="tech-tag">Java</span>
              <span class="tech-tag">Spring Boot</span>
              <span class="tech-tag">Spring Cloud</span>
              <span class="tech-tag">Docker</span>
              <span class="tech-tag">Microservices</span>
              <span class="tech-tag">WebFlux</span>
            </div>
          </div>
          <div class="project-card" data-project-type="software">
            <div class="project-badge project-badge-software">‚ö° Software</div>
            <div class="project-header">
              <h3 class="project-title">Real-Time Log File Processing Microservice</h3>
              <div class="project-links">
                <a href="https://github.com/habeneyasu/log-processing-microservice" target="_blank" class="project-link" aria-label="View Real-Time Log File Processing Microservice on GitHub" rel="noopener noreferrer">GitHub</a>
              </div>
            </div>
            <p class="project-description">
              Built Next.js + Node.js microservice processing 1GB+ log files in less than 5 minutes. Created React 
              dashboard with WebSocket integration providing sub-50ms latency updates. Implemented RESTful API with 
              Supabase integration and JWT authentication.
            </p>
            <p class="project-impact"><strong>Impact:</strong> Processes large log files 10x faster than traditional methods, enabling real-time monitoring and analysis with minimal latency.</p>
            <div class="project-tech">
              <span class="tech-tag">Node.js</span>
              <span class="tech-tag">Next.js</span>
              <span class="tech-tag">React</span>
              <span class="tech-tag">WebSocket</span>
              <span class="tech-tag">Supabase</span>
              <span class="tech-tag">JWT</span>
            </div>
          </div>
        </div>
    </div>
  </section>

  <!-- Education Section -->
  <section id="education" class="section">
    <div class="container">
      <h2 class="section-title">Education</h2>
      <div class="education-grid">
        <div class="education-card">
          <h3 class="education-title">M.Tech. in Computer Engineering</h3>
          <div class="education-institution">Defense University, College of Engineering</div>
          <div class="education-date">September 2019 ‚Äì December 2021 | Bishoftu, Ethiopia</div>
        </div>
        <div class="education-card">
          <h3 class="education-title">B.Sc. in Information Technology (Engineering)</h3>
          <div class="education-institution">Mekelle University</div>
          <div class="education-date">September 2011 ‚Äì July 2016 | Mekelle, Ethiopia</div>
        </div>
      </div>
    </div>
  </section>

  <!-- Forward-Looking Section -->
  <section id="future-focus" class="section">
    <div class="container">
      <h2 class="section-title">Looking Forward</h2>
      <div class="future-focus-content">
        <p class="future-focus-text">
          My focus is on <strong>applied AI in fintech</strong>‚Äîbuilding trustworthy, production-grade systems that enhance financial inclusion 
          while maintaining the reliability standards that financial services demand. I'm particularly interested in:
        </p>
        <ul class="future-focus-list">
          <li><strong>Scalable National Platforms:</strong> Architecting infrastructure that can serve millions of users across Ethiopia and beyond, enabling digital financial services at scale.</li>
          <li><strong>Trustworthy AI:</strong> Developing explainable, auditable AI systems that meet regulatory requirements while driving real business value.</li>
          <li><strong>Intelligent Automation:</strong> Creating self-optimizing systems that reduce operational overhead and improve system resilience through AI-driven insights.</li>
          <li><strong>Financial Inclusion:</strong> Building systems that expand access to financial services for underserved populations through alternative data and innovative risk models.</li>
  </ul>
        <p class="future-focus-text">
          I'm committed to bridging the gap between traditional banking reliability and cutting-edge AI, creating systems that are both 
          transformative and trustworthy.
        </p>
      </div>
    </div>
  </section>

  <!-- Contact Section -->
  <section id="contact" class="section section-alt">
    <div class="container">
      <h2 class="section-title">Get In Touch</h2>
      <div class="contact-content">
        <p class="contact-description">
          I'm always open to discussing new opportunities, interesting projects, or potential 
          collaborations. Whether you're looking for a Senior Software Engineer or interested in 
          AI/ML initiatives, feel free to reach out.
        </p>
        <p class="contact-cta">
          <strong>Open to collaboration, mentorship, and impact-driven opportunities.</strong>
        </p>
        <div class="contact-methods-grid">
          <a href="mailto:habeneyasu@gmail.com" class="contact-method" aria-label="Send email to habeneyasu@gmail.com">
            <div class="contact-icon">‚úâÔ∏è</div>
            <div class="contact-info">
              <div class="contact-label">Email</div>
              <div class="contact-value">habeneyasu@gmail.com</div>
            </div>
          </a>
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="contact-method" aria-label="Visit LinkedIn profile" rel="noopener noreferrer">
            <div class="contact-icon">üíº</div>
            <div class="contact-info">
              <div class="contact-label">LinkedIn</div>
              <div class="contact-value">linkedin.com/in/habeneyasu</div>
            </div>
          </a>
          <a href="https://github.com/habeneyasu" target="_blank" class="contact-method" aria-label="Visit GitHub profile" rel="noopener noreferrer">
            <div class="contact-icon">üíª</div>
            <div class="contact-info">
              <div class="contact-label">GitHub</div>
              <div class="contact-value">github.com/habeneyasu</div>
            </div>
          </a>
          <a href="tel:+251942707424" class="contact-method" aria-label="Call +251 942 707 424">
            <div class="contact-icon">üì±</div>
            <div class="contact-info">
              <div class="contact-label">Phone</div>
              <div class="contact-value">+251 942 707 424</div>
            </div>
          </a>
        </div>
        <div class="contact-resume">
          <a href="Haben_Eyasu_Akelom_Resume.pdf" class="btn btn-resume-contact" id="resume-download-contact" aria-label="Download resume PDF" download="Haben_Eyasu_Akelom_Resume.pdf">
            <span>üìÑ</span> Download Resume
          </a>
        </div>
      </div>
    </div>
  </section>
  </main>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="footer-content">
        <div class="footer-text">
          <p>&copy; 2025 Haben Eyasu Akelom. All rights reserved.</p>
          <p class="footer-note">Built with passion for software engineering and AI innovation</p>
        </div>
        <div class="footer-social">
          <a href="https://linkedin.com/in/habeneyasu" target="_blank" class="footer-social-link" aria-label="Visit LinkedIn profile" rel="noopener noreferrer">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
              <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/>
            </svg>
            LinkedIn
          </a>
          <a href="https://github.com/habeneyasu" target="_blank" class="footer-social-link" aria-label="Visit GitHub profile" rel="noopener noreferrer">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true">
              <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
            </svg>
            GitHub
          </a>
        </div>
      </div> 
    </div>
  </footer>

  <script>
    // Mobile Navigation Toggle
    (function() {
      try {
        const navToggle = document.querySelector('.nav-toggle');
        const navMenu = document.querySelector('.nav-menu');
        
        if (navToggle && navMenu) {
          navToggle.addEventListener('click', function() {
            const isExpanded = navToggle.getAttribute('aria-expanded') === 'true';
            navToggle.setAttribute('aria-expanded', !isExpanded);
            navMenu.classList.toggle('nav-menu-active');
            navToggle.classList.toggle('nav-toggle-active');
          });

          // Close menu when clicking on a link
          const navLinks = navMenu.querySelectorAll('a');
          navLinks.forEach(link => {
            link.addEventListener('click', () => {
              navMenu.classList.remove('nav-menu-active');
              navToggle.classList.remove('nav-toggle-active');
              navToggle.setAttribute('aria-expanded', 'false');
            });
          });
        }
      } catch (error) {
        console.error('Error initializing mobile navigation:', error);
      }
    })();

    // Smooth scrolling for navigation links
    (function() {
      try {
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
          anchor.addEventListener('click', function (e) {
            const href = this.getAttribute('href');
            if (href === '#') return;
            
            e.preventDefault();
            const target = document.querySelector(href);
            if (target) {
              target.scrollIntoView({
                behavior: 'smooth',
                block: 'start'
              });
            }
          });
        });
      } catch (error) {
        console.error('Error initializing smooth scroll:', error);
      }
    })();

    // Animated Counters
    (function() {
      try {
        const animateCounter = (element) => {
          const target = parseFloat(element.getAttribute('data-target'));
          const suffix = element.getAttribute('data-suffix') || '';
          const duration = 2000; // 2 seconds
          const increment = target / (duration / 16); // 60fps
          let current = 0;
          
          // Get initial value from element text (fallback)
          const initialText = element.textContent.trim();
          if (initialText && initialText !== '0' && !initialText.match(/^0[%+]?$/)) {
            // If element already has a value, use it as starting point
            const match = initialText.match(/^([\d.]+)/);
            if (match) {
              current = parseFloat(match[1]);
            }
          }

          const updateCounter = () => {
            current += increment;
            if (current < target) {
              if (suffix === '%') {
                element.textContent = current.toFixed(1) + suffix;
              } else if (suffix.includes('M+')) {
                element.textContent = Math.floor(current) + suffix;
              } else {
                element.textContent = Math.floor(current) + suffix;
              }
              requestAnimationFrame(updateCounter);
            } else {
              element.textContent = target + suffix;
            }
          };

          updateCounter();
        };

        const observerOptions = {
          threshold: 0.5,
          rootMargin: '0px'
        };

        const observer = new IntersectionObserver((entries) => {
          entries.forEach(entry => {
            if (entry.isIntersecting && !entry.target.classList.contains('counted')) {
              entry.target.classList.add('counted');
              animateCounter(entry.target);
              observer.unobserve(entry.target);
            }
          });
        }, observerOptions);

        const counters = document.querySelectorAll('.stat-number[data-target]');
        counters.forEach(counter => observer.observe(counter));
      } catch (error) {
        console.error('Error initializing counters:', error);
        // Fallback: show static numbers
        document.querySelectorAll('.stat-number[data-target]').forEach(el => {
          const target = el.getAttribute('data-target');
          const suffix = el.getAttribute('data-suffix') || '';
          el.textContent = target + suffix;
        });
      }
    })();

    // Add scroll effect to navbar and active navigation states
    (function() {
      try {
        const sections = document.querySelectorAll('section[id]');
        const navLinks = document.querySelectorAll('.nav-menu a[href^="#"]');
        
        window.addEventListener('scroll', function() {
          const navbar = document.querySelector('.navbar');
          if (navbar) {
            if (window.scrollY > 50) {
              navbar.classList.add('navbar-scrolled');
            } else {
              navbar.classList.remove('navbar-scrolled');
            }
          }

          // Update active navigation link
          let current = '';
          sections.forEach(section => {
            const sectionTop = section.offsetTop;
            const sectionHeight = section.clientHeight;
            if (window.scrollY >= (sectionTop - 200)) {
              current = section.getAttribute('id');
            }
          });

          navLinks.forEach(link => {
            link.classList.remove('nav-active');
            if (link.getAttribute('href') === `#${current}`) {
              link.classList.add('nav-active');
            }
          });
        });
      } catch (error) {
        console.error('Error initializing navbar scroll effect:', error);
      }
    })();

    // Resume Download Handler - Simple tracking only, no interference
    (function() {
      try {
        const resumeLinks = document.querySelectorAll('.btn-resume, .btn-resume-contact');
        resumeLinks.forEach(link => {
          // Just track clicks, don't interfere with download
          link.addEventListener('click', function() {
            console.log('Resume download clicked');
            // Download will happen automatically via download attribute
          });
        });
      } catch (error) {
        console.error('Error initializing resume download:', error);
      }
    })();
  </script>
</body>
</html>
